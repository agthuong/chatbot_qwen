import streamlit as st
from qwen_agent.agents import Assistant
from qwen_agent.tools.base import BaseTool, register_tool
import json5
import os
import datetime
import json
import re
# import time # Streamlit x·ª≠ l√Ω timing kh√°c
# import unidecode # Kh√¥ng c·∫ßn cho RAG si√™u ƒë∆°n gi·∫£n
# from sklearn.feature_extraction.text import TfidfVectorizer # Kh√¥ng embedding
# from sklearn.metrics.pairwise import cosine_similarity # Kh√¥ng search
# import numpy as np # Kh√¥ng c·∫ßn numpy
# from fuzzywuzzy import fuzz # C√≥ th·ªÉ kh√¥ng c·∫ßn thi·∫øt n·ªØa

# --- C√°c bi·∫øn to√†n c·ª•c cho c·∫•u h√¨nh ---
LLM_CFG = {
    'model': 'qwen1.5-32b-chat-q4_0',
    'model_server': 'http://localhost:1234/v1',
    'api_key': 'EMPTY',
    'generate_cfg': {'temperature': 0.1}
}

RAW_RAG_SYSTEM_PROMPT = """B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng d·ª±a TR√äN N·ªòI DUNG ƒê∆Ø·ª¢C CUNG C·∫§P. 
To√†n b·ªô n·ªôi dung t√†i li·ªáu li√™n quan s·∫Ω ƒë∆∞·ª£c cung c·∫•p cho b·∫°n ngay sau c√¢u "D∆∞·ªõi ƒë√¢y l√† n·ªôi dung t√†i li·ªáu:". 
H√£y ƒë·ªçc k·ªπ t√†i li·ªáu n√†y v√† c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi ch√≠nh x√°c nh·∫•t. 
**Quan tr·ªçng: C·ªë g·∫Øng hi·ªÉu √Ω ƒë·ªãnh th·ª±c s·ª± c·ªßa ng∆∞·ªùi d√πng, ngay c·∫£ khi c√¢u h·ªèi c√≥ v·∫ª ch·ª©a l·ªói ch√≠nh t·∫£ ho·∫∑c t·ª´ vi·∫øt t·∫Øt kh√¥ng r√µ r√†ng. V√≠ d·ª•, n·∫øu ng∆∞·ªùi d√πng h·ªèi 'giai doan cuoi amf gi', h√£y xem x√©t kh·∫£ nƒÉng h·ªç mu·ªën h·ªèi 'giai ƒëo·∫°n cu·ªëi l√†m g√¨' ho·∫∑c 'giai ƒëo·∫°n cu·ªëi l√† g√¨' v√† t√¨m th√¥ng tin t∆∞∆°ng ·ª©ng trong t√†i li·ªáu.**
Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin c√≥ trong t√†i li·ªáu. N·∫øu th√¥ng tin kh√¥ng c√≥ trong t√†i li·ªáu, h√£y n√≥i r√µ "Th√¥ng tin n√†y kh√¥ng c√≥ trong t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p.".
Tr√¨nh b√†y c√¢u tr·∫£ l·ªùi m·ªôt c√°ch r√µ r√†ng v√† s√∫c t√≠ch.
"""

# Bi·∫øn to√†n c·ª•c ƒë·ªÉ theo d√µi tr·∫°ng th√°i ƒëƒÉng k√Ω tools
TOOLS_REGISTERED = False

# --- ƒê·ªãnh nghƒ©a c√°c class tool (kh√¥ng ƒëƒÉng k√Ω ·ªü ƒë√¢y) ---
class TraCuuQuyTrinhTextRawTool(BaseTool):
    description = 'Cung c·∫•p to√†n b·ªô n·ªôi dung t·ª´ file vƒÉn b·∫£n ƒë·ªÉ LLM t·ª± t√¨m ki·∫øm th√¥ng tin tr·∫£ l·ªùi c√¢u h·ªèi.'
    parameters = [
        {'name': 'trigger', 'type': 'string', 'description': 'M·ªôt chu·ªói b·∫•t k·ª≥ ƒë·ªÉ k√≠ch ho·∫°t tool l·∫•y n·ªôi dung file.', 'required': False }
    ]
    def __init__(self, *args, **kwargs):
        super().__init__()
        self.data_file_path = './test_data.txt'
        self.full_text_content = self._load_full_text_content(self.data_file_path)
        if self.full_text_content is None:
            st.warning(f"Tool: L·ªñI - Kh√¥ng th·ªÉ t·∫£i n·ªôi dung t·ª´ {self.data_file_path}.")

    def _load_full_text_content(self, file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f: content = f.read()
            return content
        except FileNotFoundError: st.error(f"Tool: File not found {file_path}"); return None
        except Exception as e: st.error(f"Tool: Error reading file {file_path}: {e}"); return None

    def call(self, params: str, **kwargs):
        if self.full_text_content is not None:
            return {'success': True, 'full_document_content': self.full_text_content}
        else:
            return {'success': False, 'error': f'Tool: Kh√¥ng th·ªÉ t·∫£i n·ªôi dung t·ª´ file {self.data_file_path}.'}

class TraCuuQuyTrinhCSVTool(BaseTool):
    description = 'Tra c·ª©u th√¥ng tin quy tr√¨nh c√¥ng vi·ªác t·ª´ CSDL CSV. Cung c·∫•p th√¥ng tin ch√≠nh x√°c v·ªÅ c√°c quy tr√¨nh c·ªßa c√¥ng ty.'
    parameters = [{
        'name': 'query',
        'type': 'string',
        'description': 'C√¢u h·ªèi v·ªÅ quy tr√¨nh c·∫ßn t√¨m. C√≥ th·ªÉ bao g·ªìm t·ª´ kh√≥a v·ªÅ giai ƒëo·∫°n, ph√≤ng ban, c√¥ng vi·ªác, ng∆∞·ªùi th·ª±c hi·ªán.',
        'required': True
    }]

    def __init__(self, *args, **kwargs):
        super().__init__()
        self.data_file_path = './data.csv'
        try:
            # Ch·ªâ ki·ªÉm tra xem file c√≥ t·ªìn t·∫°i kh√¥ng, kh√¥ng ƒë·ªçc h·∫øt n·ªôi dung
            with open(self.data_file_path, 'r', encoding='utf-8') as f:
                self.file_exists = True
        except FileNotFoundError:
            st.error(f"Tool: File CSV not found {self.data_file_path}")
            self.file_exists = False
        except Exception as e:
            st.error(f"Tool: Error checking CSV file {self.data_file_path}: {e}")
            self.file_exists = False

    def call(self, params: str, **kwargs):
        if not self.file_exists:
            return {'success': False, 'error': f'Tool: Kh√¥ng th·ªÉ t·∫£i n·ªôi dung t·ª´ file {self.data_file_path}.'}
        
        # Ph√¢n t√≠ch tham s·ªë ƒë·∫ßu v√†o
        try:
            if isinstance(params, str) and not params.startswith('{'):
                query = params
            else:
                query_data = json5.loads(params)
                query = query_data['query']
        except Exception as e:
            query = str(params)
        
        try:
            # ƒê·ªçc m·ªôt ph·∫ßn nh·ªè c·ªßa file ƒë·ªÉ ki·ªÉm tra
            import pandas as pd
            df_preview = pd.read_csv(self.data_file_path, nrows=5)
            
            # Tr·∫£ v·ªÅ th√¥ng tin gi·∫£n l∆∞·ª£c
            return {
                'success': True,
                'message': f'ƒê√£ t√¨m th·∫•y th√¥ng tin cho "{query}" trong file CSV. ƒê√¢y l√† d·ªØ li·ªáu c·∫•u tr√∫c v·ªõi {len(df_preview.columns)} c·ªôt.',
                'preview': df_preview.to_dict(orient='records')[:2]  # Ch·ªâ tr·∫£ v·ªÅ 2 h√†ng ƒë·∫ßu ƒë·ªÉ minh h·ªça
            }
        except Exception as e:
            return {'success': False, 'error': f'L·ªói khi ƒë·ªçc file CSV: {str(e)}'}

# --- H√†m ƒë·ªÉ l·∫•y ho·∫∑c t·∫°o tool v√† assistant d·ª±a tr√™n dataset ƒë∆∞·ª£c ch·ªçn ---
@st.cache_resource
def get_chatbot_essentials(dataset_choice):
    """
    Kh·ªüi t·∫°o v√† tr·∫£ v·ªÅ assistant ph√π h·ª£p v·ªõi dataset ƒë∆∞·ª£c ch·ªçn
    
    Args:
        dataset_choice: Chu·ªói ch·ªâ ƒë·ªãnh dataset ƒë∆∞·ª£c ch·ªçn ("text" ho·∫∑c "csv")
    
    Returns:
        Tuple (assistant, document_content)
    """
    global TOOLS_REGISTERED
    
    # ƒêƒÉng k√Ω tools n·∫øu ch∆∞a ƒë∆∞·ª£c ƒëƒÉng k√Ω
    if not TOOLS_REGISTERED:
        # ƒêƒÉng k√Ω tools v·ªõi allow_overwrite=True ƒë·ªÉ tr√°nh l·ªói n·∫øu ƒë√£ t·ªìn t·∫°i
        text_tool_cls = register_tool('tra_cuu_quy_trinh_text_raw', allow_overwrite=True)(TraCuuQuyTrinhTextRawTool)
        csv_tool_cls = register_tool('tra_cuu_quy_trinh_csv', allow_overwrite=True)(TraCuuQuyTrinhCSVTool)
        TOOLS_REGISTERED = True
        st.success("Tools ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω th√†nh c√¥ng!")
    
    # L·ª±a ch·ªçn function t∆∞∆°ng ·ª©ng v·ªõi dataset
    if dataset_choice == "text":
        function_list = ["tra_cuu_quy_trinh_text_raw"]
        # L·∫•y n·ªôi dung c·ªßa file text
        tool_instance = TraCuuQuyTrinhTextRawTool()
        document_content = tool_instance.full_text_content
    else:  # "csv"
        function_list = ["tra_cuu_quy_trinh_csv"]
        # V·ªõi file CSV, ch√∫ng ta ch·ªâ ki·ªÉm tra xem file c√≥ t·ªìn t·∫°i kh√¥ng
        tool_instance = TraCuuQuyTrinhCSVTool()
        if tool_instance.file_exists:
            document_content = "File CSV ƒë√£ ƒë∆∞·ª£c t·∫£i. D·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c truy xu·∫•t khi c·∫ßn."
        else:
            document_content = None
            st.error("Kh√¥ng th·ªÉ t√¨m th·∫•y file data.csv. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
    
    # Kh·ªüi t·∫°o assistant v·ªõi function list t∆∞∆°ng ·ª©ng
    assistant = Assistant(
        llm=LLM_CFG,
        function_list=function_list,
        system_message=RAW_RAG_SYSTEM_PROMPT
    )
    
    if document_content is None:
        st.error(f"L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng th·ªÉ t·∫£i n·ªôi dung t√†i li·ªáu cho dataset {dataset_choice}.")
    
    return assistant, document_content

# H√†m x·ª≠ l√Ω <think> tag ƒë·ªÉ hi·ªÉn th·ªã trong collapse box
def format_think_tags(text):
    """Chuy·ªÉn ƒë·ªïi <think>...</think> th√†nh ƒë·ªãnh d·∫°ng details/summary c·ªßa HTML"""
    pattern = r'<think>(.*?)</think>'
    
    def replace_func(match):
        think_content = match.group(1).strip()
        return f"""
<details>
<summary>üí≠ Suy nghƒ© c·ªßa AI (nh·∫•n ƒë·ªÉ xem/·∫©n)</summary>
<div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; margin: 10px 0;">
{think_content}
</div>
</details>
"""
    
    # Thay th·∫ø t·∫•t c·∫£ c√°c th·∫ª <think> trong vƒÉn b·∫£n
    formatted_text = re.sub(pattern, replace_func, text, flags=re.DOTALL)
    return formatted_text

# Ki·ªÉm tra xem chunk c√≥ ch·ª©a th·∫ª <think> hay kh√¥ng
def chunk_contains_think_tag(chunk):
    return '<think>' in chunk or '</think>' in chunk

# --- H√†m ch√≠nh cho ·ª©ng d·ª•ng Streamlit ---
def run_chatbot_app():
    st.title("ü§ñ Chatbot Quy Tr√¨nh (RAW RAG)")

    # B·∫≠t HTML rendering ƒë·ªÉ hi·ªÉn th·ªã details/summary
    st.markdown("""
    <style>
    details {
        border: 1px solid #aaa;
        border-radius: 4px;
        padding: .5em .5em 0;
        margin-bottom: 1em;
    }
    summary {
        font-weight: bold;
        cursor: pointer;
        padding: .5em;
        color: #4b8bf4;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # --- Sidebar ƒë·ªÉ c·∫•u h√¨nh ---
    with st.sidebar:
        st.header("C·∫•u h√¨nh Chatbot")
        
        # Radio button ƒë·ªÉ ch·ªçn dataset
        if "dataset_choice" not in st.session_state:
            st.session_state.dataset_choice = "text"  # M·∫∑c ƒë·ªãnh l√† dataset text
            
        dataset_choice = st.radio(
            "Ch·ªçn ngu·ªìn d·ªØ li·ªáu:",
            options=["text", "csv"],
            format_func=lambda x: "File Text (test_data.txt)" if x == "text" else "File CSV (data.csv)",
            key="dataset_choice"
        )
        
        st.info(f"ƒê√£ ch·ªçn dataset: {dataset_choice}")
        
        # N√∫t ƒë·ªÉ x√≥a l·ªãch s·ª≠ chat
        if st.button("X√≥a l·ªãch s·ª≠ chat"):
            st.session_state.messages = []
            st.success("ƒê√£ x√≥a l·ªãch s·ª≠ chat!")

    # Kh·ªüi t·∫°o assistant d·ª±a v√†o l·ª±a ch·ªçn dataset
    assistant, main_document_content = get_chatbot_essentials(st.session_state.dataset_choice)

    if main_document_content is None:
        st.error("Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông chatbot do l·ªói t·∫£i t√†i li·ªáu.")
        return
    
    if assistant is None:
        st.error("Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông chatbot do l·ªói kh·ªüi t·∫°o Assistant.")
        return

    # Kh·ªüi t·∫°o l·ªãch s·ª≠ chat n·∫øu ch∆∞a c√≥
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            # S·ª≠ d·ª•ng unsafe_allow_html ƒë·ªÉ hi·ªÉn th·ªã HTML
            st.markdown(message["content"], unsafe_allow_html=True)

    # X·ª≠ l√Ω input t·ª´ ng∆∞·ªùi d√πng
    if prompt := st.chat_input("C√¢u h·ªèi c·ªßa b·∫°n v·ªÅ t√†i li·ªáu?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Th√™m ng·ªØ c·∫£nh v√†o prompt d·ª±a tr√™n lo·∫°i dataset
        if st.session_state.dataset_choice == "text":
            user_message_with_context = f"{prompt}\n\n---\nD∆∞·ªõi ƒë√¢y l√† n·ªôi dung t√†i li·ªáu:\n{main_document_content}"
        else:  # csv
            user_message_with_context = prompt  # Kh√¥ng c·∫ßn th√™m ng·ªØ c·∫£nh v√¨ tool s·∫Ω truy c·∫≠p file CSV tr·ª±c ti·∫øp
        
        prepared_messages_for_llm = []
        if len(st.session_state.messages) > 1:
            prepared_messages_for_llm.extend(st.session_state.messages[:-1])
        prepared_messages_for_llm.append({'role': 'user', 'content': user_message_with_context})

        with st.chat_message("assistant"):
            raw_full_response = ""  # L∆∞u tr·ªØ ph·∫£n h·ªìi nguy√™n b·∫£n tr∆∞·ªõc khi x·ª≠ l√Ω
            buffer = ""  # Buffer ƒë·ªÉ gi·ªØ n·ªôi dung ch∆∞a ho√†n ch·ªânh
            think_blocks = []  # L∆∞u c√°c kh·ªëi <think> ƒë√£ x·ª≠ l√Ω ƒë·ªÉ tr√°nh l·∫∑p l·∫°i
            visible_content_placeholder = st.empty()  # Placeholder cho n·ªôi dung hi·ªÉn th·ªã
            
            # S·ª≠ d·ª•ng m·ªôt spinner ƒë∆°n gi·∫£n n·∫øu mu·ªën c√≥ ch·ªâ b√°o loading
            with st.spinner("ü§ñ LLM ƒëang suy nghƒ©..."):
                try:
                    # Generator n√†y s·∫Ω x·ª≠ l√Ω t·ª´ng chunk v√† tr√≠ch xu·∫•t ph·∫ßn n·ªôi dung m·ªõi
                    def generate_responses_for_streaming_and_history():
                        nonlocal raw_full_response, buffer, think_blocks
                        assistant_responded_flag = False
                        previous_text = ""  # L∆∞u to√†n b·ªô vƒÉn b·∫£n tr∆∞·ªõc ƒë√≥
                        
                        for r_chunk_list in assistant.run(messages=prepared_messages_for_llm):
                            if r_chunk_list:
                                last_message_in_chunk = r_chunk_list[-1]
                                if last_message_in_chunk.get('role') == 'assistant':
                                    current_chunk = last_message_in_chunk.get('content', '')
                                    if current_chunk:  # Ch·ªâ x·ª≠ l√Ω n·∫øu c√≥ n·ªôi dung
                                        # T√¨m ph·∫ßn n·ªôi dung m·ªõi (delta) gi·ªØa chunk hi·ªán t·∫°i v√† vƒÉn b·∫£n tr∆∞·ªõc ƒë√≥
                                        if current_chunk.startswith(previous_text) and current_chunk != previous_text:
                                            # Ch·ªâ l·∫•y ph·∫ßn m·ªõi ƒë∆∞·ª£c th√™m v√†o
                                            new_content = current_chunk[len(previous_text):]
                                            if new_content:  # Ch·ªâ yield n·∫øu c√≥ n·ªôi dung m·ªõi
                                                raw_full_response += new_content
                                                buffer += new_content
                                                previous_text = current_chunk
                                                yield (buffer, False)  # False = kh√¥ng ph·∫£i n·ªôi dung cu·ªëi c√πng
                                        else:
                                            # N·∫øu kh√¥ng ph·∫£i l√† ti·∫øp n·ªëi c·ªßa vƒÉn b·∫£n tr∆∞·ªõc
                                            # (hi·∫øm khi x·∫£y ra, nh∆∞ng ƒë·ªÉ ph√≤ng ng·ª´a)
                                            raw_full_response = current_chunk
                                            buffer = current_chunk
                                            previous_text = current_chunk
                                            yield (buffer, False)
                                    assistant_responded_flag = True
                        
                        if not assistant_responded_flag and not raw_full_response:
                            fallback_msg = "Xin l·ªói, t√¥i kh√¥ng th·ªÉ t·∫°o ph·∫£n h·ªìi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p."
                            raw_full_response = fallback_msg
                            buffer = fallback_msg
                            yield (buffer, True)  # True = n·ªôi dung cu·ªëi c√πng
                        else:
                            yield (buffer, True)  # Ph√°t ra n·ªôi dung cu·ªëi c√πng
                    
                    # X·ª≠ l√Ω t·ª´ng chunk ƒë∆∞·ª£c tr·∫£ v·ªÅ
                    for content, is_final in generate_responses_for_streaming_and_history():
                        # X·ª≠ l√Ω v√† hi·ªÉn th·ªã n·ªôi dung t·∫°m th·ªùi
                        formatted_content = format_think_tags(content)
                        visible_content_placeholder.markdown(formatted_content, unsafe_allow_html=True)
                    
                    # Sau khi stream k·∫øt th√∫c, x·ª≠ l√Ω n·ªôi dung ƒë·∫ßy ƒë·ªß
                    full_processed_response = format_think_tags(raw_full_response)

                except Exception as e:
                    st.error(f"L·ªói khi ch·∫°y assistant: {e}")
                    full_processed_response = "Xin l·ªói, t√¥i g·∫∑p s·ª± c·ªë khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n."
            
            # C·∫≠p nh·∫≠t n·ªôi dung cu·ªëi c√πng
            visible_content_placeholder.markdown(full_processed_response, unsafe_allow_html=True)
            
            # L∆∞u v√†o l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán
            st.session_state.messages.append({"role": "assistant", "content": full_processed_response})

if __name__ == "__main__":
    run_chatbot_app()

# ƒê·ªÉ ch·∫°y ·ª©ng d·ª•ng n√†y:
# 1. ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√†i ƒë·∫∑t streamlit: pip install streamlit (version >= 1.29.0 ƒë·ªÉ c√≥ st.write_stream)
# 2. L∆∞u file n√†y (v√≠ d·ª•: chatbot_qwen/run_local_from_text.py)
# 3. Ch·∫°y t·ª´ terminal: streamlit run chatbot_qwen/run_local_from_text.py