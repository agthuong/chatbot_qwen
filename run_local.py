from qwen_agent.agents import Assistant
from qwen_agent.tools.base import BaseTool, register_tool
import pandas as pd
import json5
import os
import datetime
import json
import time
from fuzzywuzzy import fuzz  # ThÃªm thÆ° viá»‡n so sÃ¡nh má»

# ğŸ”§ Import tool Ä‘á»‹nh nghÄ©a á»Ÿ file khÃ¡c náº¿u cÃ³
# VÃ­ dá»¥: from tools import csv_tool

@register_tool('tra_cuu_quy_trinh')
class TraCuuQuyTrinhTool(BaseTool):
    description = 'Tra cá»©u thÃ´ng tin quy trÃ¬nh cÃ´ng viá»‡c tá»« CSDL. Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c vá» cÃ¡c quy trÃ¬nh cá»§a cÃ´ng ty.'
    parameters = [{
        'name': 'query',
        'type': 'string',
        'description': 'CÃ¢u há»i vá» quy trÃ¬nh cáº§n tÃ¬m. CÃ³ thá»ƒ bao gá»“m tá»« khÃ³a vá» giai Ä‘oáº¡n, phÃ²ng ban, cÃ´ng viá»‡c, ngÆ°á»i thá»±c hiá»‡n.',
        'required': True
    }]

    def __init__(self, *args, **kwargs):
        super().__init__()
        import pandas as pd
        import numpy as np
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.metrics.pairwise import cosine_similarity
        import re
        import unidecode  # ThÃªm thÆ° viá»‡n xá»­ lÃ½ dáº¥u tiáº¿ng Viá»‡t
        
        # Táº£i dá»¯ liá»‡u
        self.df = pd.read_csv('./data.csv')
        
        # In thÃ´ng tin dáº¡ng dá»¯ liá»‡u Ä‘á»ƒ debug
        print("TÃªn cÃ¡c cá»™t trong file CSV:", self.df.columns.tolist())
        
        # Kiá»ƒm tra xem cÃ³ cá»™t 'Unnamed' nÃ o khÃ´ng
        has_unnamed_columns = any('Unnamed' in col for col in self.df.columns)
        
        # PhÃ¢n tÃ­ch xem file CSV sá»­ dá»¥ng tÃªn cá»™t tháº­t hay Unnamed
        if has_unnamed_columns:
            # PhÆ°Æ¡ng phÃ¡p cÅ© náº¿u cÃ³ cá»™t Unnamed
            self.use_unnamed_columns = True
            try:
                header_row = self.df.iloc[1]
                actual_headers = {}
                
                # Láº¥y tÃªn cá»™t thá»±c táº¿ tá»« dÃ²ng header
                for i, col_name in enumerate(self.df.columns):
                    if i < len(header_row) and isinstance(header_row[i], str) and header_row[i].strip():
                        actual_headers[header_row[i]] = col_name
                        print(f"Header thá»±c táº¿: '{header_row[i]}' á»Ÿ cá»™t '{col_name}'")
                
                # In thÃ´ng tin vá» header Ä‘Ã£ phÃ¢n tÃ­ch
                print(f"ÄÃ£ phÃ¢n tÃ­ch Ä‘Æ°á»£c {len(actual_headers)} header thá»±c táº¿ tá»« CSV")
            except Exception as e:
                print(f"Lá»—i khi phÃ¢n tÃ­ch header: {e}")
                actual_headers = {}
                
            # Kiá»ƒm tra vÃ  loáº¡i bá» cÃ¡c hÃ ng tiÃªu Ä‘á»/metadata 
            first_rows = self.df.iloc[:5]
            is_header = []
            
            for i, row in first_rows.iterrows():
                header_like_count = sum(1 for x in row if isinstance(x, str) and 
                    (x.istitle() or x.isupper() or x in ['A', 'R'] or 
                     any(term in x for term in ['Giai Ä‘oáº¡n', 'CÃ´ng viá»‡c', 'PhÃ²ng ban', 'Má»¥c tiÃªu'])))
                is_header.append(header_like_count > 3)
            
            # Táº¡o danh sÃ¡ch cÃ¡c chá»‰ sá»‘ cáº§n loáº¡i bá»
            drop_indices = [i for i, is_h in enumerate(is_header) if is_h and i < 5]
            
            # Loáº¡i bá» cÃ¡c hÃ ng header báº±ng index
            if drop_indices:
                self.df = self.df.drop(drop_indices).reset_index(drop=True)
                
            # Cáº­p nháº­t Ã¡nh xáº¡ tÃªn cá»™t dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿ trong file CSV
            self.column_names = {
                'Giai Ä‘oáº¡n': actual_headers.get('Giai Ä‘oáº¡n', 'Unnamed: 1'),
                'CÃ´ng viá»‡c': actual_headers.get('CÃ´ng viá»‡c', 'Unnamed: 2'),
                'PhÃ²ng ban': actual_headers.get('PhÃ²ng ban', 'Unnamed: 3'),
                'Äiá»u kiá»‡n tiÃªn quyáº¿t': actual_headers.get('Äiá»u kiá»‡n tiÃªn quyáº¿t', 'Unnamed: 4'),
                'NgÆ°á»i phá»¥ trÃ¡ch': actual_headers.get('A', 'Unnamed: 5'),  # Cá»™t A
                'NgÆ°á»i thá»±c hiá»‡n': actual_headers.get('R', 'Unnamed: 6'),  # Cá»™t R
                'LÃ m gÃ¬': actual_headers.get('LÃ m gÃ¬', 'Unnamed: 7'),
                'Má»¥c tiÃªu': actual_headers.get('Má»¥c tiÃªu', 'Unnamed: 8'),
                'Káº¿t quáº£ tráº£ ra': actual_headers.get('Káº¿t quáº£ tráº£ ra', 'Unnamed: 9'),
                'Duration': actual_headers.get('Duration', 'Unnamed: 10'),
                'Receiver': actual_headers.get('Receiver', 'Unnamed: 11'),
                'Äá»‹nh ká»³ thá»±c hiá»‡n': actual_headers.get('Äá»‹nh ká»³ thá»±c hiá»‡n', 'Unnamed: 12'),
                'Gá»­i káº¿t quáº£ qua': actual_headers.get('Gá»­i káº¿t quáº£ qua', 'Unnamed: 13'),
                'Form thá»±c hiá»‡n': actual_headers.get('Form thá»±c hiá»‡n', 'Unnamed: 14'),
                'Äo lÆ°á»ng/Ä‘Ã¡nh giÃ¡': actual_headers.get('Äo lÆ°á»ng/Ä‘Ã¡nh giÃ¡', 'Unnamed: 15')
            }
        else:
            # PhÆ°Æ¡ng phÃ¡p má»›i náº¿u cÃ³ tÃªn cá»™t tháº­t
            self.use_unnamed_columns = False
            # Lá»c dá»¯ liá»‡u trá»‘ng
            # Kiá»ƒm tra xem dÃ²ng Ä‘áº§u tiÃªn cÃ³ pháº£i lÃ  header khÃ´ng
            if pd.isna(self.df.iloc[0]['Giai Ä‘oáº¡n']) or self.df.iloc[0]['Giai Ä‘oáº¡n'] == '':
                self.df = self.df.iloc[1:].reset_index(drop=True)
                
            # Ãnh xáº¡ trá»±c tiáº¿p tÃªn cá»™t
            self.column_names = {
                'Giai Ä‘oáº¡n': 'Giai Ä‘oáº¡n',
                'CÃ´ng viá»‡c': 'CÃ´ng viá»‡c',
                'PhÃ²ng ban': 'PhÃ²ng ban',
                'Äiá»u kiá»‡n tiÃªn quyáº¿t': 'Äiá»u kiá»‡n tiÃªn quyáº¿t',
                'NgÆ°á»i phá»¥ trÃ¡ch': 'A',  # Cá»™t A
                'NgÆ°á»i thá»±c hiá»‡n': 'R',  # Cá»™t R
                'LÃ m gÃ¬': 'LÃ m gÃ¬',
                'Má»¥c tiÃªu': 'Má»¥c tiÃªu',
                'Káº¿t quáº£ tráº£ ra': 'Káº¿t quáº£ tráº£ ra',
                'Duration': 'Duration',
                'Receiver': 'Receiver',
                'Äá»‹nh ká»³ thá»±c hiá»‡n': 'Äá»‹nh ká»³ thá»±c hiá»‡n',
                'Gá»­i káº¿t quáº£ qua': 'Gá»­i káº¿t quáº£ qua',
                'Form thá»±c hiá»‡n': 'Form thá»±c hiá»‡n',
                'Äo lÆ°á»ng/Ä‘Ã¡nh giÃ¡': 'Äo lÆ°á»ng/Ä‘Ã¡nh giÃ¡'
            }
            
        # Lá»c dá»¯ liá»‡u trá»‘ng má»™t cÃ¡ch cháº·t cháº½ hÆ¡n
        content_mask = np.array([
            sum(1 for x in row if pd.notna(x) and str(x).strip() != '') > 3 
            for _, row in self.df.iterrows()
        ])
        
        self.df = self.df[content_mask].reset_index(drop=True)
        
        # Sá»­a lá»—i fillna
        for col in self.df.columns:
            if self.df[col].dtype == 'float64' or self.df[col].dtype == 'int64':
                self.df[col].fillna(0, inplace=True)
            else:
                self.df[col].fillna('', inplace=True)
        
        # In ra thá»‘ng kÃª Ä‘á»ƒ kiá»ƒm tra
        print(f"Dá»¯ liá»‡u sau khi lá»c: {len(self.df)} hÃ ng, {len(self.df.columns)} cá»™t")
        
        # In ra Ã¡nh xáº¡ tÃªn cá»™t Ä‘á»ƒ kiá»ƒm tra
        print("Ãnh xáº¡ tÃªn cá»™t:")
        for friendly_name, col_name in self.column_names.items():
            print(f"  {friendly_name} -> {col_name}")
        
        # Táº¡o tá»« Ä‘iá»ƒn map ngÆ°á»£c láº¡i Ä‘á»ƒ tiá»‡n sá»­ dá»¥ng
        self.inverse_column_names = {v: k for k, v in self.column_names.items()}
        
        # HÃ m tiá»n xá»­ lÃ½ vÄƒn báº£n (lÃ m sáº¡ch vÃ  chuáº©n hÃ³a)
        def preprocess_text(text):
            if not isinstance(text, str):
                return ""
            # Chuyá»ƒn sang chá»¯ thÆ°á»ng
            text = text.lower()
            # Loáº¡i bá» dáº¥u cÃ¢u vÃ  kÃ½ tá»± Ä‘áº·c biá»‡t
            text = re.sub(r'[^\w\s]', ' ', text)
            # Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
            text = re.sub(r'\s+', ' ', text).strip()
            # Táº¡o phiÃªn báº£n khÃ´ng dáº¥u Ä‘á»ƒ há»— trá»£ tÃ¬m kiáº¿m khÃ´ng phÃ¢n biá»‡t dáº¥u
            text_no_accent = unidecode.unidecode(text)
            # Káº¿t há»£p cáº£ vÄƒn báº£n gá»‘c vÃ  khÃ´ng dáº¥u
            return text + " " + text_no_accent
        
        # LÆ°u láº¡i hÃ m tiá»n xá»­ lÃ½ vÄƒn báº£n Ä‘á»ƒ sá»­ dá»¥ng sau nÃ y
        self.preprocess_text = preprocess_text
        
        # Danh sÃ¡ch stopwords tiáº¿ng Viá»‡t má»Ÿ rá»™ng
        self.vietnamese_stopwords = [
            'vÃ ', 'hoáº·c', 'cá»§a', 'lÃ ', 'Ä‘á»ƒ', 'trong', 'ngoÃ i', 'khi', 'vá»›i', 'bá»Ÿi', 
            'Ä‘Æ°á»£c', 'khÃ´ng', 'cÃ³', 'nÃ y', 'Ä‘Ã³', 'cÃ¡c', 'nhá»¯ng', 'mÃ ', 'nÃªn', 'vÃ¬',
            'trÃªn', 'dÆ°á»›i', 'táº¡i', 'tá»«', 'qua', 'má»™t', 'hai', 'ba', 'bá»‘n', 'nÄƒm',
            'sÃ¡u', 'báº£y', 'tÃ¡m', 'chÃ­n', 'mÆ°á»i', 'rá»“i', 'sáº½', 'Ä‘ang', 'Ä‘Ã£', 'sáº¯p',
            'ai', 'tÃ´i', 'báº¡n', 'há»', 'chÃºng', 'chÃºng ta', 'mÃ¬nh', 'chiáº¿c', 'cÃ¡i'
        ]
        
        # XÃ¢y dá»±ng Ã¡nh xáº¡ vai trÃ² - giai Ä‘oáº¡n
        self.build_role_stage_mapping()
        
        # Táº¡o cÃ¡c trÆ°á»ng tÃ¬m kiáº¿m theo chá»§ Ä‘á»
        self.build_search_fields()
        
    def build_role_stage_mapping(self):
        """XÃ¢y dá»±ng Ã¡nh xáº¡ tá»± Ä‘á»™ng giá»¯a ngÆ°á»i thá»±c hiá»‡n vÃ  giai Ä‘oáº¡n"""
        role_stage_map = {}
        
        for idx, row in self.df.iterrows():
            role_col = self.column_names['NgÆ°á»i thá»±c hiá»‡n']
            stage_col = self.column_names['Giai Ä‘oáº¡n']
            
            if (isinstance(row[role_col], str) and row[role_col].strip() and 
                isinstance(row[stage_col], str) and row[stage_col].strip()):
                
                # TÃ¡ch cÃ¡c vai trÃ² náº¿u cÃ³ nhiá»u (phÃ¢n tÃ¡ch bá»Ÿi dáº¥u pháº©y)
                roles = [r.strip().lower() for r in row[role_col].split(',')]
                stage = row[stage_col].strip()
                
                for role in roles:
                    if role not in role_stage_map:
                        role_stage_map[role] = []
                    if stage not in role_stage_map[role]:
                        role_stage_map[role].append(stage)
        
        self.role_stage_mapping = role_stage_map
        
        # In ra Ä‘á»ƒ kiá»ƒm tra
        print(f"ÄÃ£ xÃ¢y dá»±ng Ã¡nh xáº¡ vai trÃ² - giai Ä‘oáº¡n cho {len(role_stage_map)} vai trÃ².")

    def build_search_fields(self):
        """Táº¡o cÃ¡c trÆ°á»ng tÃ¬m kiáº¿m theo ngá»¯ nghÄ©a vÃ  chá»‰ má»¥c vector tÆ°Æ¡ng á»©ng cho táº¥t cáº£ cá»™t"""
        import numpy as np
        from sklearn.feature_extraction.text import TfidfVectorizer
        
        # Táº¡o cÃ¡c trÆ°á»ng tÃ¬m kiáº¿m chÃ­nh
        # 1. TrÆ°á»ng nhÃ¢n sá»±
        self.df['person_fields'] = self.df.apply(
            lambda row: ' '.join([
                str(row[self.column_names['NgÆ°á»i thá»±c hiá»‡n']]), 
                str(row[self.column_names['NgÆ°á»i phá»¥ trÃ¡ch']])
            ]), axis=1).apply(self.preprocess_text)
        
        # 2. TrÆ°á»ng quy trÃ¬nh
        self.df['process_fields'] = self.df.apply(
            lambda row: ' '.join([
                str(row[self.column_names['Giai Ä‘oáº¡n']]), 
                str(row[self.column_names['CÃ´ng viá»‡c']]), 
                str(row[self.column_names['PhÃ²ng ban']])
            ]), axis=1).apply(self.preprocess_text)
        
        # 3. TrÆ°á»ng ná»™i dung
        self.df['content_fields'] = self.df.apply(
            lambda row: ' '.join([
                str(row[self.column_names['Má»¥c tiÃªu']]), 
                str(row[self.column_names['LÃ m gÃ¬']]), 
                str(row[self.column_names['Káº¿t quáº£ tráº£ ra']])
            ]), axis=1).apply(self.preprocess_text)
            
        # 4. TrÆ°á»ng thá»i gian vÃ  táº§n suáº¥t
        self.df['time_fields'] = self.df.apply(
            lambda row: ' '.join([
                str(row[self.column_names['Äá»‹nh ká»³ thá»±c hiá»‡n']]), 
                str(row[self.column_names['Duration']])
            ]), axis=1).apply(self.preprocess_text)
        
        # 5. TrÆ°á»ng thÃ´ng tin bá»• sung
        self.df['additional_fields'] = self.df.apply(
            lambda row: ' '.join([
                str(row[self.column_names.get('Äiá»u kiá»‡n tiÃªn quyáº¿t', '')]),
                str(row[self.column_names.get('Receiver', '')]),
                str(row[self.column_names.get('Gá»­i káº¿t quáº£ qua', '')]),
                str(row[self.column_names.get('Form thá»±c hiá»‡n', '')]),
                str(row[self.column_names.get('Äo lÆ°á»ng/Ä‘Ã¡nh giÃ¡', '')])
            ]), axis=1).apply(self.preprocess_text)
        
        # Táº¡o trÆ°á»ng tÃ¬m kiáº¿m tá»•ng há»£p cÃ³ trá»ng sá»‘
        self.df['search_text'] = ''
        
        # NhÃ¢n trá»ng sá»‘ cho cÃ¡c trÆ°á»ng khÃ¡c nhau
        field_weights = {
            'process_fields': 3,    # Trá»ng sá»‘ cao nháº¥t cho thÃ´ng tin quy trÃ¬nh
            'content_fields': 2,    # Trá»ng sá»‘ cao cho ná»™i dung
            'person_fields': 1,     # Trá»ng sá»‘ bÃ¬nh thÆ°á»ng cho ngÆ°á»i thá»±c hiá»‡n
            'time_fields': 2,       # TÄƒng trá»ng sá»‘ cho thÃ´ng tin thá»i gian
            'additional_fields': 1  # Trá»ng sá»‘ tháº¥p cho thÃ´ng tin bá»• sung
        }
        
        for field, weight in field_weights.items():
            weighted_text = self.df[field].apply(lambda x: ' '.join([x] * weight))
            self.df['search_text'] += ' ' + weighted_text
        
        # Vector hÃ³a trÆ°á»ng nhÃ¢n sá»±
        self.person_vectorizer = TfidfVectorizer(
            lowercase=True,
            max_df=0.9, min_df=1, 
            ngram_range=(1, 2))
        self.person_matrix = self.person_vectorizer.fit_transform(self.df['person_fields'])
        
        # Vector hÃ³a trÆ°á»ng quy trÃ¬nh
        self.process_vectorizer = TfidfVectorizer(
            lowercase=True, 
            max_df=0.9, min_df=1, 
            ngram_range=(1, 3))
        self.process_matrix = self.process_vectorizer.fit_transform(self.df['process_fields'])
        
        # Vector hÃ³a trÆ°á»ng ná»™i dung
        self.content_vectorizer = TfidfVectorizer(
            lowercase=True, 
            max_df=0.9, min_df=1, 
            ngram_range=(1, 3),
            stop_words=self.vietnamese_stopwords)
        self.content_matrix = self.content_vectorizer.fit_transform(self.df['content_fields'])
        
        # Vector hÃ³a trÆ°á»ng thá»i gian
        self.time_vectorizer = TfidfVectorizer(
            lowercase=True, 
            max_df=0.9, min_df=1, 
            ngram_range=(1, 2))
        self.time_matrix = self.time_vectorizer.fit_transform(self.df['time_fields'])
        
        # Vector hÃ³a trÆ°á»ng thÃ´ng tin bá»• sung
        self.additional_vectorizer = TfidfVectorizer(
            lowercase=True, 
            max_df=0.9, min_df=1, 
            ngram_range=(1, 2))
        self.additional_matrix = self.additional_vectorizer.fit_transform(self.df['additional_fields'])
        
        # Vector hÃ³a tá»«ng cá»™t riÃªng láº» Ä‘á»ƒ tÃ¬m kiáº¿m chÃ­nh xÃ¡c
        self.column_matrices = {}
        self.column_vectorizers = {}
        
        # Táº¡o vector cho tá»«ng cá»™t trong CSV Ä‘á»ƒ tÃ¬m kiáº¿m chÃ­nh xÃ¡c
        for col_name, actual_col in self.column_names.items():
            if actual_col in self.df.columns:
                # Tiá»n xá»­ lÃ½ vÄƒn báº£n trong cá»™t
                processed_col_text = self.df[actual_col].astype(str).apply(self.preprocess_text)
                
                # Táº¡o vectorizer cho cá»™t
                vectorizer = TfidfVectorizer(
                    lowercase=True,
                    max_df=0.95, min_df=1,
                    ngram_range=(1, 2))
                
                try:
                    # Táº¡o ma tráº­n vector cho cá»™t
                    matrix = vectorizer.fit_transform(processed_col_text)
                    
                    # LÆ°u trá»¯ cáº£ vectorizer vÃ  ma tráº­n
                    self.column_vectorizers[col_name] = vectorizer
                    self.column_matrices[col_name] = matrix
                    
                    print(f"ÄÃ£ táº¡o ma tráº­n vector cho cá»™t '{col_name}'")
                except Exception as e:
                    print(f"Lá»—i khi vector hÃ³a cá»™t '{col_name}': {e}")
        
        # Vector hÃ³a trÆ°á»ng tá»•ng há»£p cho tÃ¬m kiáº¿m máº·c Ä‘á»‹nh
        self.main_vectorizer = TfidfVectorizer(
            lowercase=True,
            ngram_range=(1, 3),
            stop_words=self.vietnamese_stopwords,
            max_features=10000,
            min_df=1,
            max_df=0.95,
            token_pattern=r'\b\w+\b'
        )
        self.main_matrix = self.main_vectorizer.fit_transform(self.df['search_text'])

    def call(self, params: str, **kwargs):
        """TÃ¬m kiáº¿m quy trÃ¬nh dá»±a trÃªn query"""
        import pandas as pd
        import numpy as np
        import json
        import json5
        from fuzzywuzzy import fuzz
        
        # PhÃ¢n tÃ­ch tham sá»‘ Ä‘áº§u vÃ o
        try:
            # Náº¿u params Ä‘Ã£ lÃ  chuá»—i query, dÃ¹ng trá»±c tiáº¿p
            if isinstance(params, str) and not params.startswith('{'):
                query = params
            # Náº¿u params lÃ  JSON string, parse nÃ³
            else:
                query_data = json5.loads(params)
                query = query_data['query']
        except Exception as e:
            # Fallback: náº¿u cÃ³ lá»—i khi parse JSON, coi params lÃ  query trá»±c tiáº¿p
            print(f"Lá»—i khi xá»­ lÃ½ tham sá»‘: {e}, dÃ¹ng params lÃ m query.")
            query = str(params)
        
        # PhÃ¢n tÃ­ch truy váº¥n
        query_info = self.analyze_query(query)
        
        # Thiáº¿t láº­p sá»‘ lÆ°á»£ng káº¿t quáº£ tráº£ vá»
        max_results = 10 if 'time_focus' in query_info['components'] else 3
        
        # TÃ¬m kiáº¿m Ä‘a chiá»u dá»±a trÃªn loáº¡i truy váº¥n
        search_results = self.multi_vector_search(query_info, top_n=max_results)
        
        # Äáº·c biá»‡t xá»­ lÃ½ truy váº¥n vá» thá»i gian
        if ('time_focus' in query_info['components'] and not search_results) or ('dinh_ky' in query_info['components']):
            # TÃ¬m kiáº¿m trá»±c tiáº¿p theo Ä‘á»‹nh ká»³ thá»±c hiá»‡n
            time_col = self.column_names['Äá»‹nh ká»³ thá»±c hiá»‡n']
            direct_results = []
            time_unit = query_info['components'].get('time_unit', '')
            
            # Náº¿u cÃ³ Ä‘Æ¡n vá»‹ thá»i gian cá»¥ thá»ƒ, tÃ¬m trá»±c tiáº¿p
            if time_unit:
                print(f"TÃ¬m kiáº¿m trá»±c tiáº¿p vá»›i Ä‘Æ¡n vá»‹ thá»i gian: {time_unit}")
                for idx in range(len(self.df)):
                    if isinstance(self.df.iloc[idx][time_col], str) and time_unit in self.df.iloc[idx][time_col].lower():
                        # TÃ­nh Ä‘iá»ƒm sá»‘ cÆ¡ báº£n cá»™ng thÃªm Ä‘iá»ƒm cho sá»‘ tá»« khÃ³a khá»›p
                        keyword_matches = sum(1 for kw in query_info['components']['keywords'] 
                                             if kw in str(self.df.iloc[idx]).lower())
                        score = 0.6 + min(0.3, keyword_matches * 0.05)
                        direct_results.append((idx, score))
                
                if direct_results:
                    # Sáº¯p xáº¿p theo Ä‘iá»ƒm sá»‘
                    direct_results = sorted(direct_results, key=lambda x: x[1], reverse=True)
                    print(f"TÃ¬m Ä‘Æ°á»£c {len(direct_results)} káº¿t quáº£ trá»±c tiáº¿p cho '{time_unit}'")
                    # Tráº£ vá» táº¥t cáº£ cÃ¡c káº¿t quáº£ tÃ¬m Ä‘Æ°á»£c thay vÃ¬ chá»‰ láº¥y top 3
                    search_results = direct_results[:max_results]
        
        # Náº¿u khÃ´ng cÃ³ káº¿t quáº£, tráº£ vá» thÃ´ng bÃ¡o
        if not search_results:
            suggestions = []
            
            # Äá» xuáº¥t dá»±a trÃªn loáº¡i truy váº¥n
            if 'time_focus' in query_info['components']:
                time_col = self.column_names['Äá»‹nh ká»³ thá»±c hiá»‡n']
                # Láº¥y cÃ¡c giÃ¡ trá»‹ Ä‘á»‹nh ká»³ thá»±c táº¿ tá»« dá»¯ liá»‡u
                unique_periods = [p for p in self.df[time_col].dropna().unique() 
                                 if isinstance(p, str) and p.strip()]
                
                if unique_periods:
                    period_examples = ", ".join(unique_periods[:3])
                    suggestions.append(f"thá»­ tÃ¬m vá»›i Ä‘á»‹nh ká»³ cá»¥ thá»ƒ nhÆ°: {period_examples}")
            
            return {
                'success': False,
                'error': 'KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p',
                'query_info': query_info,
                'suggestions': suggestions,
                'results': []
            }
        
        # Lá»c bá» cÃ¡c káº¿t quáº£ cÃ³ Ä‘iá»ƒm sá»‘ quÃ¡ tháº¥p
        min_threshold = 0.15
        filtered_results = [(idx, score) for idx, score in search_results if score > min_threshold]
        
        # Náº¿u khÃ´ng cÃ²n káº¿t quáº£ sau khi lá»c, tráº£ vá» thÃ´ng bÃ¡o
        if not filtered_results:
            return {
                'success': False,
                'error': 'KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p hoáº·c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng quÃ¡ tháº¥p',
                'query_info': query_info,
                'results': []
            }
        
        # Kiá»ƒm tra xem cÃ³ pháº£i lÃ  truy váº¥n vá» vai trÃ² vÃ  giai Ä‘oáº¡n khÃ´ng
        is_role_stage_query = False
        role = None
        expected_stages = []
        
        if 'nguoi_thuc_hien' in query_info['components'] and query_info['components']['nguoi_thuc_hien']:
            role = query_info['components']['nguoi_thuc_hien'].lower()
            if role in self.role_stage_mapping:
                expected_stages = self.role_stage_mapping[role]
                is_role_stage_query = any(term in query.lower() for term in ['thuá»™c', 'giai Ä‘oáº¡n', 'lÃ m viá»‡c'])
        
        # Kiá»ƒm tra xem cÃ³ pháº£i lÃ  truy váº¥n vá» thá»i gian khÃ´ng
        is_time_query = 'time_focus' in query_info['components']
        time_unit = query_info['components'].get('time_unit', '')
        
        # Chuáº©n bá»‹ káº¿t quáº£ tráº£ vá»
        results = []
        already_included_stages = set()  # Äá»ƒ trÃ¡nh trÃ¹ng láº·p giai Ä‘oáº¡n
        
        role_col = self.column_names['NgÆ°á»i thá»±c hiá»‡n']
        stage_col = self.column_names['Giai Ä‘oáº¡n']
        time_col = self.column_names['Äá»‹nh ká»³ thá»±c hiá»‡n']
        
        for idx, score in filtered_results:
            row = self.df.iloc[idx]
            
            # Kiá»ƒm tra vÃ  loáº¡i bá» cÃ¡c káº¿t quáº£ náº¿u lÃ  tiÃªu Ä‘á» hoáº·c hÃ ng header
            is_header = False
            row_text = ' '.join([str(v) for v in row.values if isinstance(v, str)])
            header_patterns = ['quy trÃ¬nh', 'giai Ä‘oáº¡n', 'phÃ²ng ban', 'ngÆ°á»i thá»±c hiá»‡n', 'má»¥c tiÃªu', 'output']
            if sum(1 for pattern in header_patterns if pattern.lower() in row_text.lower()) >= 3:
                is_header = True
            
            # Xá»­ lÃ½ truy váº¥n vá» vai trÃ² thuá»™c giai Ä‘oáº¡n nÃ o
            if is_role_stage_query and role:
                # Náº¿u hÃ ng khÃ´ng cÃ³ vai trÃ² phÃ¹ há»£p, bá» qua
                if not (isinstance(row[role_col], str) and role in row[role_col].lower()):
                    if score < 0.4:  # Váº«n giá»¯ láº¡i cÃ¡c káº¿t quáº£ cÃ³ Ä‘iá»ƒm cao
                        continue
                
                # Náº¿u lÃ  truy váº¥n vá» giai Ä‘oáº¡n, Æ°u tiÃªn hiá»ƒn thá»‹ cÃ¡c giai Ä‘oáº¡n khÃ¡c nhau
                if isinstance(row[stage_col], str) and row[stage_col].strip():
                    stage = row[stage_col].strip().lower()
                    if stage in already_included_stages and score < 0.5:
                        continue
                    already_included_stages.add(stage)
                
                # TÄƒng Ä‘iá»ƒm cho cÃ¡c káº¿t quáº£ cÃ³ giai Ä‘oáº¡n dá»± kiáº¿n
                if isinstance(row[stage_col], str) and any(exp_stage.lower() in row[stage_col].lower() for exp_stage in expected_stages):
                    score *= 1.2  # TÄƒng Ä‘iá»ƒm thÃªm 20%
            
            # Xá»­ lÃ½ truy váº¥n vá» thá»i gian
            if is_time_query and time_unit:
                # Æ¯u tiÃªn cÃ¡c káº¿t quáº£ cÃ³ thá»i gian phÃ¹ há»£p
                if not (isinstance(row[time_col], str) and time_unit.lower() in row[time_col].lower()):
                    if score < 0.5:  # Váº«n giá»¯ láº¡i cÃ¡c káº¿t quáº£ cÃ³ Ä‘iá»ƒm cao
                        continue
                else:
                    # TÄƒng Ä‘iá»ƒm cho káº¿t quáº£ phÃ¹ há»£p vá»›i Ä‘Æ¡n vá»‹ thá»i gian
                    score *= 1.3  # TÄƒng Ä‘iá»ƒm thÃªm 30%
            
            # Bá» qua náº¿u lÃ  header hoáº·c táº¥t cáº£ cÃ¡c cá»™t Ä‘á»u trá»‘ng
            if is_header or pd.isnull(row).all():
                continue
                
            # Táº¡o tá»« Ä‘iá»ƒn káº¿t quáº£ sá»­ dá»¥ng Ã¡nh xáº¡ tÃªn cá»™t thay vÃ¬ hard-coding
            result = {'score': score}
            
            # ThÃªm cÃ¡c trÆ°á»ng dá»¯ liá»‡u cÃ³ Ã½ nghÄ©a, sá»­ dá»¥ng tÃªn cá»™t thÃ¢n thiá»‡n
            for col, value in row.items():
                if pd.notna(value) and str(value).strip():
                    # Sá»­ dá»¥ng tÃªn thÃ¢n thiá»‡n náº¿u cÃ³, náº¿u khÃ´ng thÃ¬ giá»¯ nguyÃªn tÃªn cá»™t
                    friendly_name = self.inverse_column_names.get(col, col)
                    # Chuyá»ƒn Ä‘á»•i tÃªn trÆ°á»ng sang dáº¡ng snake_case Ä‘á»ƒ dá»… sá»­ dá»¥ng
                    field_name = friendly_name.lower().replace(' ', '_').replace('/', '_')
                    result[field_name] = value
            
            # Náº¿u chÆ°a cÃ³ giai Ä‘oáº¡n nhÆ°ng cÃ³ thá»ƒ suy ra tá»« cÃ¡c hÃ ng trÆ°á»›c
            if 'giai_Ä‘oáº¡n' not in result or not result['giai_Ä‘oáº¡n'] and idx > 0:
                # TÃ¬m trong cÃ¡c hÃ ng trÃªn Ä‘á»ƒ láº¥y thÃ´ng tin giai Ä‘oáº¡n
                for i in range(idx-1, -1, -1):
                    prev_stage = self.df.iloc[i][stage_col]
                    if isinstance(prev_stage, str) and prev_stage.strip():
                        result['giai_Ä‘oáº¡n'] = prev_stage
                        break
            
            # Äáº£m báº£o cÃ¡c trÆ°á»ng quan trá»ng luÃ´n cÃ³ máº·t trong káº¿t quáº£
            essential_fields = ['giai_Ä‘oáº¡n', 'cÃ´ng_viá»‡c', 'phÃ²ng_ban', 'ngÆ°á»i_thá»±c_hiá»‡n', 'má»¥c_tiÃªu']
            for field in essential_fields:
                if field not in result:
                    result[field] = ''
            
            results.append(result)
        
        # Náº¿u lÃ  truy váº¥n vá» vai trÃ² thuá»™c giai Ä‘oáº¡n nÃ o vÃ  khÃ´ng cÃ³ káº¿t quáº£ cá»¥ thá»ƒ
        # Tráº£ vá» cÃ¡c giai Ä‘oáº¡n tá»« báº£n Ä‘á»“ Ã¡nh xáº¡
        if is_role_stage_query and role and not results:
            if expected_stages:
                for stage in expected_stages:
                    result = {
                        'giai_Ä‘oáº¡n': stage,
                        'ngÆ°á»i_thá»±c_hiá»‡n': role.capitalize(),
                        'score': 0.7  # Äiá»ƒm máº·c Ä‘á»‹nh cho káº¿t quáº£ tá»« Ã¡nh xáº¡
                    }
                    results.append(result)
        
        # Náº¿u lÃ  truy váº¥n vá» thá»i gian vÃ  khÃ´ng cÃ³ káº¿t quáº£ cá»¥ thá»ƒ
        if is_time_query and time_unit and not results:
            # TÃ¬m kiáº¿m trá»±c tiáº¿p má»™t láº§n ná»¯a vá»›i ngÆ°á»¡ng tháº¥p hÆ¡n
            direct_time_results = []
            for idx in range(len(self.df)):
                if isinstance(self.df.iloc[idx][time_col], str) and time_unit.lower() in self.df.iloc[idx][time_col].lower():
                    row = self.df.iloc[idx].to_dict()
                    # Chá»‰ láº¥y nhá»¯ng trÆ°á»ng khÃ´ng trá»‘ng
                    result = {
                        'score': 0.6,
                        'Ä‘á»‹nh_ká»³_thá»±c_hiá»‡n': self.df.iloc[idx][time_col]
                    }
                    
                    # ThÃªm cÃ¡c trÆ°á»ng quan trá»ng
                    for field, col_name in [
                        ('giai_Ä‘oáº¡n', self.column_names['Giai Ä‘oáº¡n']),
                        ('cÃ´ng_viá»‡c', self.column_names['CÃ´ng viá»‡c']),
                        ('phÃ²ng_ban', self.column_names['PhÃ²ng ban']),
                        ('ngÆ°á»i_thá»±c_hiá»‡n', self.column_names['NgÆ°á»i thá»±c hiá»‡n'])
                    ]:
                        if col_name in row and pd.notna(row[col_name]) and str(row[col_name]).strip():
                            result[field] = row[col_name]
                        else:
                            result[field] = ''
                    
                    direct_time_results.append(result)
            
            if direct_time_results:
                print(f"TÃ¬m Ä‘Æ°á»£c {len(direct_time_results)} káº¿t quáº£ bá»• sung cho '{time_unit}'")
                # Láº¥y táº¥t cáº£ káº¿t quáº£, tá»‘i Ä‘a 10 káº¿t quáº£
                results = direct_time_results[:max_results]
        
        # Dá»¯ liá»‡u káº¿t quáº£ cuá»‘i cÃ¹ng
        response = {
            'success': True,
            'query_info': query_info,
            'results': self.prepare_results_for_response(query, query_info, filtered_results) if not results else {'results': results}
        }
        
        # Tráº£ vá» káº¿t quáº£ dÆ°á»›i dáº¡ng JSON string hoáº·c dict tÃ¹y theo yÃªu cáº§u
        if kwargs.get('return_json', False):
            return json.dumps(response, ensure_ascii=False)
        return response
    
    def extract_role_terms(self, text):
        """TrÃ­ch xuáº¥t cÃ¡c tá»« khÃ³a vá» vai trÃ² tá»« vÄƒn báº£n"""
        # Láº¥y táº¥t cáº£ vai trÃ² tá»« cá»™t NgÆ°á»i thá»±c hiá»‡n
        all_roles = set()
        role_col = self.column_names['NgÆ°á»i thá»±c hiá»‡n']
        
        for val in self.df[role_col].dropna().unique():
            if isinstance(val, str):
                roles = [r.strip().lower() for r in val.split(',')]
                all_roles.update(roles)
        
        # Kiá»ƒm tra tá»«ng vai trÃ² cÃ³ trong vÄƒn báº£n khÃ´ng
        found_roles = []
        for role in all_roles:
            if role in text.lower():
                found_roles.append(role)
        
        return found_roles
    
    def analyze_query(self, query):
        """PhÃ¢n tÃ­ch truy váº¥n vÃ  xÃ¡c Ä‘á»‹nh loáº¡i truy váº¥n"""
        import re
        import unidecode
        
        query_info = {
            'original': query,
            'processed': query.lower(),
            'query_type': 'general',
            'search_focus': [],
            'components': {
                'giai_doan': None,
                'phong_ban': None,
                'cong_viec': None,
                'keywords': []
            }
        }
        
        # PhÃ¡t hiá»‡n truy váº¥n vá» ngÆ°á»i/nhÃ¢n sá»±
        person_terms = ['ai', 'ngÆ°á»i', 'nhÃ¢n viÃªn', 'nhÃ¢n sá»±', 'thá»±c hiá»‡n', 'phá»¥ trÃ¡ch', 'leader', 'team']
        
        # PhÃ¡t hiá»‡n truy váº¥n vá» quy trÃ¬nh
        process_terms = ['giai Ä‘oáº¡n', 'quy trÃ¬nh', 'cÃ´ng viá»‡c', 'phÃ²ng ban', 'bá»™ pháº­n', 'thuá»™c']
        
        # PhÃ¡t hiá»‡n truy váº¥n vá» má»¥c tiÃªu/káº¿t quáº£
        content_terms = ['má»¥c tiÃªu', 'lÃ m gÃ¬', 'káº¿t quáº£', 'nhiá»‡m vá»¥', 'trÃ¡ch nhiá»‡m', 'cÃ´ng viá»‡c', 'output']
        
        # PhÃ¡t hiá»‡n truy váº¥n vá» thá»i gian vÃ  táº§n suáº¥t
        time_terms = ['hÃ ng ngÃ y', 'ngÃ y', 'tuáº§n', 'thÃ¡ng', 'quÃ½', 'nÄƒm', 'Ä‘á»‹nh ká»³', 'thÆ°á»ng xuyÃªn', 
                     'táº§n suáº¥t', 'khi nÃ o', 'bao lÃ¢u', 'thá»i gian', 'duration', 'always on']
        
        # Äáº¿m sá»‘ lÆ°á»£ng tá»« khÃ³a theo tá»«ng loáº¡i
        person_count = sum(1 for term in person_terms if term in query.lower())
        process_count = sum(1 for term in process_terms if term in query.lower())
        content_count = sum(1 for term in content_terms if term in query.lower())
        time_count = sum(1 for term in time_terms if term in query.lower())
        
        # XÃ¡c Ä‘á»‹nh má»¥c tiÃªu chÃ­nh cá»§a truy váº¥n
        if person_count > 0:
            query_info['search_focus'].append('person')
        if process_count > 0:
            query_info['search_focus'].append('process')
        if content_count > 0:
            query_info['search_focus'].append('content')
        if time_count > 0:
            query_info['search_focus'].append('time')
            query_info['components']['time_focus'] = True
            
            # TrÃ­ch xuáº¥t thÃ´ng tin vá» Ä‘Æ¡n vá»‹ thá»i gian cá»¥ thá»ƒ
            for term in time_terms:
                if term in query.lower():
                    query_info['components']['time_unit'] = term
                    break
        
        # Náº¿u khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c, tÃ¬m kiáº¿m tá»•ng quÃ¡t
        if not query_info['search_focus']:
            query_info['search_focus'] = ['process', 'content', 'person']
        
        # Tá»« Ä‘iá»ƒn biáº¿n thá»ƒ má»Ÿ rá»™ng
        common_variations = {
            'telesale': 'telesales',
            'tele sale': 'telesales',
            'phone sale': 'telesales',
            'marketing': 'mkt',
            'kinh doanh': 'sales',
            'kd': 'sales', 
            'mkt': 'marketing',
            'tiáº¿p thá»‹': 'marketing',
            'branding': 'branding mkt',
            'data': 'data qualification',
            'nguá»“n': 'sales sourcing',
            'thiáº¿t káº¿': 'design',
            'tÃ¬m kiáº¿m': 'sales sourcing',
            'xÃ¡c Ä‘á»‹nh': 'data qualification',
            'tiáº¿p cáº­n': 'approach',
            'khÃ¡ch hÃ ng': 'customer',
            'Ä‘áº¡i lÃ½': 'agency',
            'nhÃ¢n sá»±': 'hr',
            'nhÃ¢n lá»±c': 'hr',
            'tuyá»ƒn dá»¥ng': 'hr',
            'hÃ ng thÃ¡ng': 'thÃ¡ng',
            'hÃ ng tuáº§n': 'tuáº§n',
            'hÃ ng nÄƒm': 'nÄƒm',
            'hÃ ng quÃ½': 'quÃ½',
            'Ä‘á»‹nh ká»³ thÃ¡ng': 'thÃ¡ng',
            'Ä‘á»‹nh ká»³ tuáº§n': 'tuáº§n',
            'Ä‘á»‹nh ká»³ nÄƒm': 'nÄƒm'
        }
        
        # Chuáº©n hÃ³a query
        processed_query = query.lower()
        for variation, standard in common_variations.items():
            pattern = r'\b' + variation + r'\b' 
            processed_query = re.sub(pattern, standard, processed_query)
        
        query_info['processed'] = processed_query
        
        # TrÃ­ch xuáº¥t vai trÃ² tá»« truy váº¥n
        role_terms = self.extract_role_terms(processed_query)
        
        # Xá»­ lÃ½ chung cho táº¥t cáº£ vai trÃ², khÃ´ng chá»‰ Telesales
        for role in role_terms:
            query_info['components']['nguoi_thuc_hien'] = role.capitalize()
            if 'person' not in query_info['search_focus']:
                query_info['search_focus'].append('person')
            
            # Náº¿u truy váº¥n liÃªn quan Ä‘áº¿n giai Ä‘oáº¡n cá»§a vai trÃ²
            if any(term in query.lower() for term in ['thuá»™c', 'giai Ä‘oáº¡n', 'lÃ m viá»‡c trong']):
                # Xá»­ lÃ½ tÃ¬m giai Ä‘oáº¡n tá»« báº£n Ä‘á»“ Ã¡nh xáº¡
                if role in self.role_stage_mapping:
                    if 'stage_keywords' not in query_info['components']:
                        query_info['components']['stage_keywords'] = []
                    
                    for stage in self.role_stage_mapping[role]:
                        query_info['components']['stage_keywords'].append(stage.lower())
                        # Náº¿u chÆ°a xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c giai Ä‘oáº¡n, láº¥y giai Ä‘oáº¡n Ä‘áº§u tiÃªn
                        if not query_info['components']['giai_doan']:
                            query_info['components']['giai_doan'] = stage
                            
                    # Äáº£m báº£o tÃ¬m kiáº¿m theo quy trÃ¬nh
                    if 'process' not in query_info['search_focus']:
                        query_info['search_focus'].append('process')
                    
                    # ThÃªm cÃ¡c tá»« khÃ³a giai Ä‘oáº¡n vÃ o tá»« khÃ³a tÃ¬m kiáº¿m
                    for stage_kw in query_info['components']['stage_keywords']:
                        words = stage_kw.split()
                        for word in words:
                            if len(word) > 3 and word not in query_info['components']['keywords']:
                                query_info['components']['keywords'].append(word)
        
        # TÃ¬m cÃ¡c giai Ä‘oáº¡n trong cÃ¢u há»i náº¿u chÆ°a xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c
        if not query_info['components']['giai_doan']:
            stages = list(self.df[self.column_names['Giai Ä‘oáº¡n']].dropna().unique()) 
            for stage in stages:
                if not isinstance(stage, str):
                    continue
                stage_lower = stage.lower()
                if stage_lower in processed_query or unidecode.unidecode(stage_lower) in unidecode.unidecode(processed_query):
                    query_info['components']['giai_doan'] = stage
                    break
        
        # TÃ¬m cÃ¡c phÃ²ng ban trong cÃ¢u há»i
        departments = list(self.df[self.column_names['PhÃ²ng ban']].dropna().unique())
        for dept in departments:
            if not isinstance(dept, str):
                continue
            dept_lower = dept.lower()
            if dept_lower in processed_query or unidecode.unidecode(dept_lower) in unidecode.unidecode(processed_query):
                query_info['components']['phong_ban'] = dept
                break
        
        # TÃ¬m cÃ¡c thÃ´ng tin vá» Ä‘á»‹nh ká»³ thá»±c hiá»‡n
        if 'time_focus' in query_info['components'] and query_info['components']['time_focus']:
            time_col = self.column_names['Äá»‹nh ká»³ thá»±c hiá»‡n']
            periodic_values = list(self.df[time_col].dropna().unique())
            
            for period in periodic_values:
                if not isinstance(period, str):
                    continue
                period_lower = period.lower()
                if period_lower in processed_query or unidecode.unidecode(period_lower) in unidecode.unidecode(processed_query):
                    query_info['components']['dinh_ky'] = period
                    break
        
        # TÃ¡ch cÃ¡c tá»« khÃ³a chÃ­nh
        for word in processed_query.split():
            if len(word) > 3 and word not in query_info['components']['keywords']:
                query_info['components']['keywords'].append(word)
        
        return query_info
    
    def multi_vector_search(self, query_info, top_n=3):
        """TÃ¬m kiáº¿m Ä‘a vector dá»±a trÃªn nhiá»u tiÃªu chÃ­ vÃ  káº¿t há»£p káº¿t quáº£"""
        import numpy as np
        from sklearn.metrics.pairwise import cosine_similarity
        
        # Äiá»u chá»‰nh top_n dá»±a vÃ o loáº¡i truy váº¥n
        if 'time_focus' in query_info['components'] and query_info['components']['time_focus']:
            # TÄƒng sá»‘ lÆ°á»£ng káº¿t quáº£ tráº£ vá» cho truy váº¥n thá»i gian
            top_n = 10  # TÄƒng lÃªn 10 káº¿t quáº£ thay vÃ¬ máº·c Ä‘á»‹nh 3
            print(f"Truy váº¥n thá»i gian: TÄƒng top_n lÃªn {top_n}")
        
        results = []
        scores = []
        
        # Táº¡o vector truy váº¥n cho cÃ¡c loáº¡i tÃ¬m kiáº¿m khÃ¡c nhau
        query_text = query_info['processed']
        
        # Trá»ng sá»‘ cho tá»«ng loáº¡i tÃ¬m kiáº¿m - Ä‘á»™ng dá»±a trÃªn loáº¡i truy váº¥n
        weights = {
            'title': 0.20,
            'person': 0.15,
            'process': 0.15,
            'content': 0.30,
            'time': 0.10,
            'additional': 0.10
        }
        
        # Äiá»u chá»‰nh trá»ng sá»‘ dá»±a trÃªn loáº¡i truy váº¥n
        if 'time_focus' in query_info['components'] and query_info['components']['time_focus']:
            # TÄƒng trá»ng sá»‘ thá»i gian náº¿u truy váº¥n liÃªn quan Ä‘áº¿n thá»i gian
            weights['time'] = 0.35
            weights['title'] = 0.15
            weights['content'] = 0.20
            weights['person'] = 0.10
            weights['process'] = 0.15
            weights['additional'] = 0.05
        
        # Láº¥y thÃ´ng tin vá» vai trÃ² vÃ  giai Ä‘oáº¡n dá»± kiáº¿n tá»« query_info
        role = None
        expected_stages = []
        if 'nguoi_thuc_hien' in query_info['components'] and query_info['components']['nguoi_thuc_hien']:
            role = query_info['components']['nguoi_thuc_hien'].lower()
            # Láº¥y danh sÃ¡ch giai Ä‘oáº¡n dá»± kiáº¿n tá»« báº£n Ä‘á»“ Ã¡nh xáº¡
            if role in self.role_stage_mapping:
                expected_stages = self.role_stage_mapping[role]
        
        # TÃ¬m kiáº¿m dá»±a trÃªn tiÃªu Ä‘á»/tÃªn giai Ä‘oáº¡n (tÃ¬m kiáº¿m tá»•ng há»£p)
        if 'process' in query_info['search_focus'] or not query_info['search_focus']:
            title_vector = self.main_vectorizer.transform([query_text])
            title_similarities = cosine_similarity(title_vector, self.main_matrix).flatten()
            
            # TÄƒng Ä‘iá»ƒm cho cÃ¡c giai Ä‘oáº¡n dá»± kiáº¿n cá»§a vai trÃ² náº¿u cÃ³
            if expected_stages and any(term in query_text for term in ['thuá»™c', 'giai Ä‘oáº¡n', 'lÃ m viá»‡c']):
                for i, index in enumerate(self.df.index):
                    stage_col = self.column_names['Giai Ä‘oáº¡n']
                    if isinstance(self.df.loc[index, stage_col], str):
                        for stage in expected_stages:
                            if stage.lower() in self.df.loc[index, stage_col].lower():
                                title_similarities[i] *= 1.5  # TÄƒng 50% Ä‘iá»ƒm
            
            for i in range(len(self.df)):
                results.append(i)
                scores.append(title_similarities[i] * weights['title'])
        
        # TÃ¬m kiáº¿m dá»±a trÃªn ngÆ°á»i thá»±c hiá»‡n
        if 'person' in query_info['search_focus']:
            person_vector = self.person_vectorizer.transform([query_text])
            person_similarities = cosine_similarity(person_vector, self.person_matrix).flatten()
            
            # TÄƒng Ä‘iá»ƒm cho hÃ ng cÃ³ vai trÃ² phÃ¹ há»£p
            if role:
                role_col = self.column_names['NgÆ°á»i thá»±c hiá»‡n']
                stage_col = self.column_names['Giai Ä‘oáº¡n']
                
                for i, index in enumerate(self.df.index):
                    if isinstance(self.df.loc[index, role_col], str) and role in self.df.loc[index, role_col].lower():
                        person_similarities[i] *= 1.8  # TÄƒng 80% Ä‘iá»ƒm
                    
                    # Náº¿u Ä‘ang tÃ¬m kiáº¿m giai Ä‘oáº¡n cá»§a vai trÃ²
                    if expected_stages and any(term in query_text for term in ['thuá»™c', 'giai Ä‘oáº¡n', 'lÃ m viá»‡c']):
                        # Giáº£m Ä‘iá»ƒm cho cÃ¡c giai Ä‘oáº¡n khÃ´ng phÃ¹ há»£p vá»›i vai trÃ²
                        if (isinstance(self.df.loc[index, stage_col], str) and 
                            not any(stage.lower() in self.df.loc[index, stage_col].lower() for stage in expected_stages)):
                            person_similarities[i] *= 0.4  # Giáº£m 60% Ä‘iá»ƒm
            
            for i in range(len(self.df)):
                if i < len(results) and results[i] == i:
                    scores[i] += person_similarities[i] * weights['person']
                else:
                    results.append(i)
                    scores.append(person_similarities[i] * weights['person'])
        
        # TÃ¬m kiáº¿m dá»±a trÃªn phÃ²ng ban & quy trÃ¬nh
        if 'process' in query_info['search_focus']:
            dept_vector = self.process_vectorizer.transform([query_text])
            dept_similarities = cosine_similarity(dept_vector, self.process_matrix).flatten()
            
            for i in range(len(self.df)):
                if i < len(results) and results[i] == i:
                    scores[i] += dept_similarities[i] * weights['process']
                else:
                    results.append(i)
                    scores.append(dept_similarities[i] * weights['process'])
        
        # TÃ¬m kiáº¿m dá»±a trÃªn ná»™i dung
        if 'content' in query_info['search_focus'] or not query_info['search_focus']:
            content_vector = self.content_vectorizer.transform([query_text])
            content_similarities = cosine_similarity(content_vector, self.content_matrix).flatten()
            
            # TÄƒng Ä‘iá»ƒm cho cÃ¡c giai Ä‘oáº¡n dá»± kiáº¿n cá»§a vai trÃ² náº¿u cÃ³
            if role and expected_stages and 'má»¥c tiÃªu' in query_text:
                role_col = self.column_names['NgÆ°á»i thá»±c hiá»‡n']
                stage_col = self.column_names['Giai Ä‘oáº¡n']
                
                for i, index in enumerate(self.df.index):
                    # Náº¿u hÃ ng vá»«a cÃ³ giai Ä‘oáº¡n phÃ¹ há»£p vá»«a cÃ³ vai trÃ² phÃ¹ há»£p
                    if (isinstance(self.df.loc[index, stage_col], str) and 
                        any(stage.lower() in self.df.loc[index, stage_col].lower() for stage in expected_stages) and
                        isinstance(self.df.loc[index, role_col], str) and
                        role in self.df.loc[index, role_col].lower()):
                        content_similarities[i] *= 2.0  # TÄƒng gáº¥p Ä‘Ã´i Ä‘iá»ƒm
            
            for i in range(len(self.df)):
                if i < len(results) and results[i] == i:
                    scores[i] += content_similarities[i] * weights['content']
                else:
                    results.append(i)
                    scores.append(content_similarities[i] * weights['content'])
        
        # TÃ¬m kiáº¿m dá»±a trÃªn thÃ´ng tin thá»i gian
        if 'time' in query_info['search_focus'] or 'time_focus' in query_info['components']:
            time_vector = self.time_vectorizer.transform([query_text])
            time_similarities = cosine_similarity(time_vector, self.time_matrix).flatten()
            
            # TÄƒng Ä‘iá»ƒm cho káº¿t quáº£ phÃ¹ há»£p vá»›i Ä‘Æ¡n vá»‹ thá»i gian cá»¥ thá»ƒ
            if 'time_unit' in query_info['components'] and query_info['components']['time_unit']:
                time_unit = query_info['components']['time_unit']
                time_col = self.column_names['Äá»‹nh ká»³ thá»±c hiá»‡n']
                
                for i, index in enumerate(self.df.index):
                    if isinstance(self.df.loc[index, time_col], str) and time_unit.lower() in self.df.loc[index, time_col].lower():
                        time_similarities[i] *= 3.0  # TÄƒng máº¡nh Ä‘iá»ƒm sá»‘ khi khá»›p Ä‘Ãºng Ä‘Æ¡n vá»‹ thá»i gian
            
            # TÄƒng Ä‘iá»ƒm cho káº¿t quáº£ phÃ¹ há»£p vá»›i Ä‘á»‹nh ká»³ cá»¥ thá»ƒ
            if 'dinh_ky' in query_info['components'] and query_info['components']['dinh_ky']:
                specified_period = query_info['components']['dinh_ky']
                time_col = self.column_names['Äá»‹nh ká»³ thá»±c hiá»‡n']
                
                for i, index in enumerate(self.df.index):
                    if isinstance(self.df.loc[index, time_col], str) and specified_period.lower() in self.df.loc[index, time_col].lower():
                        time_similarities[i] *= 5.0  # TÄƒng ráº¥t máº¡nh Ä‘iá»ƒm sá»‘ khi khá»›p chÃ­nh xÃ¡c Ä‘á»‹nh ká»³
            
            for i in range(len(self.df)):
                if i < len(results) and results[i] == i:
                    scores[i] += time_similarities[i] * weights['time']
                else:
                    results.append(i)
                    scores.append(time_similarities[i] * weights['time'])
        
        # TÃ¬m kiáº¿m dá»±a trÃªn thÃ´ng tin bá»• sung
        if 'additional' in query_info['search_focus'] or not query_info['search_focus']:
            additional_vector = self.additional_vectorizer.transform([query_text])
            additional_similarities = cosine_similarity(additional_vector, self.additional_matrix).flatten()
            
            for i in range(len(self.df)):
                if i < len(results) and results[i] == i:
                    scores[i] += additional_similarities[i] * weights['additional']
                else:
                    results.append(i)
                    scores.append(additional_similarities[i] * weights['additional'])
        
        # TÃ¬m kiáº¿m trá»±c tiáº¿p trong tá»«ng cá»™t náº¿u cáº§n
        if 'time_focus' in query_info['components'] or role or 'dinh_ky' in query_info['components']:
            # Danh sÃ¡ch cá»™t cáº§n tÃ¬m kiáº¿m trá»±c tiáº¿p
            columns_to_search = []
            
            if 'time_focus' in query_info['components']:
                columns_to_search.append('Äá»‹nh ká»³ thá»±c hiá»‡n')
                
            if role:
                columns_to_search.append('NgÆ°á»i thá»±c hiá»‡n')
                
            for col_name in columns_to_search:
                if col_name in self.column_vectorizers:
                    # Táº¡o vector truy váº¥n cho cá»™t cá»¥ thá»ƒ
                    col_vector = self.column_vectorizers[col_name].transform([query_text])
                    col_similarities = cosine_similarity(col_vector, self.column_matrices[col_name]).flatten()
                    
                    # Cáº­p nháº­t Ä‘iá»ƒm sá»‘
                    for i in range(len(self.df)):
                        if i < len(results) and results[i] == i:
                            # TÄƒng cÆ°á»ng Ä‘iá»ƒm sá»‘ cho tÃ¬m kiáº¿m trá»±c tiáº¿p
                            scores[i] += col_similarities[i] * 0.15
                        else:
                            results.append(i)
                            scores.append(col_similarities[i] * 0.15)
        
        # Káº¿t há»£p káº¿t quáº£
        result_dict = {}
        for i, idx in enumerate(results):
            if idx not in result_dict or scores[i] > result_dict[idx]:
                result_dict[idx] = scores[i]
        
        # Sáº¯p xáº¿p káº¿t quáº£ theo Ä‘iá»ƒm sá»‘
        sorted_results = sorted([(idx, score) for idx, score in result_dict.items()], 
                                key=lambda x: x[1], reverse=True)
        
        # Xá»­ lÃ½ sau cÃ¹ng cho tÃ¬m kiáº¿m theo thá»i gian
        if 'time_focus' in query_info['components'] and query_info['components']['time_focus']:
            time_col = self.column_names['Äá»‹nh ká»³ thá»±c hiá»‡n']
            time_unit = query_info['components'].get('time_unit', '')
            
            # Táº¡o danh sÃ¡ch káº¿t quáº£ phÃ¹ há»£p vá»›i Ä‘Æ¡n vá»‹ thá»i gian
            time_matching_results = []
            other_results = []
            
            for idx, score in sorted_results:
                if (isinstance(self.df.iloc[idx][time_col], str) and 
                    time_unit and time_unit.lower() in self.df.iloc[idx][time_col].lower()):
                    # TÄƒng Ä‘iá»ƒm cho káº¿t quáº£ phÃ¹ há»£p
                    time_matching_results.append((idx, score * 1.2))
                else:
                    other_results.append((idx, score))
            
            # Káº¿t há»£p káº¿t quáº£, Æ°u tiÃªn káº¿t quáº£ phÃ¹ há»£p thá»i gian
            sorted_results = sorted(time_matching_results, key=lambda x: x[1], reverse=True)
            
            # ThÃªm cÃ¡c káº¿t quáº£ khÃ¡c náº¿u cáº§n
            if len(sorted_results) < top_n:
                remaining_slots = top_n - len(sorted_results)
                sorted_results.extend(other_results[:remaining_slots])
            
            print(f"TÃ¬m Ä‘Æ°á»£c {len(time_matching_results)} káº¿t quáº£ phÃ¹ há»£p vá»›i Ä‘Æ¡n vá»‹ thá»i gian '{time_unit}'")
        
        # Loáº¡i bá» cÃ¡c káº¿t quáº£ cÃ³ Ä‘iá»ƒm sá»‘ quÃ¡ tháº¥p
        filtered_results = [(idx, score) for idx, score in sorted_results if score > 0.15]
        
        print(f"Sá»‘ káº¿t quáº£ sau khi lá»c: {len(filtered_results)}, top_n={top_n}")
        
        # Tráº£ vá» top N káº¿t quáº£
        return filtered_results[:top_n]
    
    def filter_and_rank_results(self, scores, min_threshold=0.15):
        """Lá»c vÃ  xáº¿p háº¡ng káº¿t quáº£ dá»±a trÃªn Ä‘iá»ƒm sá»‘"""
        import numpy as np
        
        # Lá»c cÃ¡c káº¿t quáº£ cÃ³ Ä‘iá»ƒm tháº¥p
        valid_indices = np.where(scores > min_threshold)[0]
        
        if len(valid_indices) == 0:
            return []
        
        # TÃ­nh Ä‘iá»ƒm cháº¥t lÆ°á»£ng dá»¯ liá»‡u cho má»—i hÃ ng
        quality_scores = np.zeros(len(scores))
        
        for idx in valid_indices:
                row = self.df.iloc[idx]
            # ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng dá»¯ liá»‡u: cÃ³ bao nhiÃªu trÆ°á»ng cÃ³ giÃ¡ trá»‹
            non_empty_fields = sum(1 for x in row if pd.notna(x) and str(x).strip() != '')
            quality_score = non_empty_fields / len(row)
            
            # Kiá»ƒm tra xem dÃ²ng nÃ y cÃ³ pháº£i lÃ  header khÃ´ng
            # Náº¿u lÃ  header, Ä‘iá»ƒm cháº¥t lÆ°á»£ng sáº½ ráº¥t tháº¥p
            if self.is_likely_header_row(row):
                quality_score = 0.01
                
            quality_scores[idx] = quality_score
        
        # Káº¿t há»£p Ä‘iá»ƒm sá»‘ tÆ°Æ¡ng Ä‘á»“ng vÃ  cháº¥t lÆ°á»£ng
        final_scores = scores * 0.7 + quality_scores * 0.3
        
        # Láº¥y top 5 káº¿t quáº£
        top_indices = final_scores.argsort()[-5:][::-1]
        return [(i, final_scores[i]) for i in top_indices if final_scores[i] > min_threshold]
    
    def is_likely_header_row(self, row):
        """Kiá»ƒm tra má»™t hÃ ng cÃ³ kháº£ nÄƒng lÃ  header khÃ´ng"""
        # Äáº¿m sá»‘ lÆ°á»£ng giÃ¡ trá»‹ cÃ³ Ä‘áº·c Ä‘iá»ƒm cá»§a header
        header_like_count = 0
        value_count = 0
        
        for col, val in row.items():
            if pd.isna(val) or str(val).strip() == '':
                continue
                
            value_count += 1
            val_str = str(val)
            
            # Kiá»ƒm tra cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a header
            if (val_str.istitle() or val_str.isupper() or 
                val_str in ['A', 'R', 'BOD', 'CEO'] or
                val_str in ['Giai Ä‘oáº¡n', 'PhÃ²ng ban', 'Má»¥c tiÃªu']):
                header_like_count += 1
        
        # Náº¿u >60% giÃ¡ trá»‹ cÃ³ Ä‘áº·c Ä‘iá»ƒm cá»§a header
        return value_count > 0 and header_like_count / value_count > 0.6
    
    def is_likely_header_value(self, value):
        """Kiá»ƒm tra má»™t giÃ¡ trá»‹ cÃ³ kháº£ nÄƒng lÃ  giÃ¡ trá»‹ header khÃ´ng"""
        if not isinstance(value, str):
            return False
            
        # CÃ¡c chuá»—i header Ä‘iá»ƒn hÃ¬nh
        header_values = ['Giai Ä‘oáº¡n', 'CÃ´ng viá»‡c', 'PhÃ²ng ban', 'Má»¥c tiÃªu',
                         'A', 'R', 'LÃ m gÃ¬', 'Káº¿t quáº£ tráº£ ra', 'Duration']
        
        if value in header_values:
            return True
            
        # Kiá»ƒm tra náº¿u viáº¿t hoa vÃ  Ä‘á»™ dÃ i ngáº¯n
        if value.isupper() and len(value) < 15:
            return True
            
        # Kiá»ƒm tra Title Case cho cÃ¡c tá»« ngáº¯n
        if value.istitle() and len(value.split()) <= 3:
            return True
            
        return False
    
    def prepare_results_for_response(self, original_query, query_info, ranked_indices_scores):
        """Chuáº©n bá»‹ káº¿t quáº£ cuá»‘i cÃ¹ng cho pháº£n há»“i"""
        import json
        
        if not ranked_indices_scores:
            suggestions = []
            
            # Äá» xuáº¥t giai Ä‘oáº¡n
            if not query_info['components']['giai_doan']:
                stages = [str(s) for s in self.df[self.column_names['Giai Ä‘oáº¡n']].dropna().unique() if isinstance(s, str) and str(s).strip()]
                if stages:
                    sample_stages = ", ".join(stages[:3]) + "..."
                    suggestions.append(f"thÃªm giai Ä‘oáº¡n cá»¥ thá»ƒ (vÃ­ dá»¥: {sample_stages})")
            
            # Äá» xuáº¥t phÃ²ng ban
            if not query_info['components']['phong_ban']:
                depts = [str(d) for d in self.df[self.column_names['PhÃ²ng ban']].dropna().unique() if isinstance(d, str) and str(d).strip()]
                if depts:
                    sample_depts = ", ".join(depts[:3]) + "..."
                    suggestions.append(f"thÃªm phÃ²ng ban cá»¥ thá»ƒ (vÃ­ dá»¥: {sample_depts})")
            
            # Äá» xuáº¥t thá»i gian náº¿u Ä‘ang tÃ¬m kiáº¿m theo thá»i gian
            if 'time_focus' in query_info['components']:
                time_col = self.column_names['Äá»‹nh ká»³ thá»±c hiá»‡n']
                periods = [str(p) for p in self.df[time_col].dropna().unique() if isinstance(p, str) and str(p).strip()]
                if periods:
                    sample_periods = ", ".join(periods[:3]) + "..."
                    suggestions.append(f"thÃªm Ä‘á»‹nh ká»³ thá»±c hiá»‡n cá»¥ thá»ƒ (vÃ­ dá»¥: {sample_periods})")
            
            suggest_text = ""
            if suggestions:
                suggest_text = f"Báº¡n cÃ³ thá»ƒ thá»­ {' hoáº·c '.join(suggestions)}."
            
            return {
                "query_info": query_info,
                "message": f"KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p vá»›i cÃ¢u há»i cá»§a báº¡n. {suggest_text}",
                "total_results": 0,
                "results": []
            }
        
        results = []
        for idx, score in ranked_indices_scores:
            row = self.df.iloc[idx]
            
            # Kiá»ƒm tra xem hÃ ng cÃ³ pháº£i lÃ  header/tiÃªu Ä‘á» hay khÃ´ng
            if self.is_likely_header_row(row):
                continue
            
            # ÄÃ¡nh giÃ¡ Ä‘á»™ phÃ¹ há»£p
            relevance = "Cao" if score > 0.5 else "Trung bÃ¬nh" if score > 0.3 else "Tháº¥p"
            
            # Chuyá»ƒn Ä‘á»•i row thÃ nh dictionary cÃ³ cáº¥u trÃºc
                result = {
                "do_phu_hop": relevance,
                "diem_so": round(score, 2)
            }
            
            # ThÃªm cÃ¡c trÆ°á»ng dá»¯ liá»‡u cÃ³ Ã½ nghÄ©a
            for col, val in row.items():
                if pd.notna(val) and str(val).strip():
                    # Sá»­ dá»¥ng tÃªn thÃ¢n thiá»‡n náº¿u cÃ³, náº¿u khÃ´ng thÃ¬ giá»¯ nguyÃªn tÃªn cá»™t
                    friendly_name = self.inverse_column_names.get(col, col)
                    # Kiá»ƒm tra náº¿u giÃ¡ trá»‹ lÃ  header/tiÃªu Ä‘á»
                    if not self.is_likely_header_value(val):
                        result[friendly_name.lower().replace(' ', '_')] = val
            
            # Kiá»ƒm tra náº¿u Ä‘Ã¢y lÃ  truy váº¥n liÃªn quan Ä‘áº¿n thá»i gian, Ä‘áº£m báº£o trÆ°á»ng thá»i gian Ä‘Æ°á»£c bao gá»“m
            if 'time_focus' in query_info['components']:
                time_col = self.column_names['Äá»‹nh ká»³ thá»±c hiá»‡n']
                time_val = row[time_col]
                if pd.notna(time_val) and str(time_val).strip():
                    result['Ä‘á»‹nh_ká»³_thá»±c_hiá»‡n'] = time_val
                    
                    # TÄƒng thÃªm Ä‘iá»ƒm náº¿u thá»i gian khá»›p vá»›i yÃªu cáº§u
                    if 'time_unit' in query_info['components']:
                        time_unit = query_info['components']['time_unit']
                        if time_unit and time_unit.lower() in str(time_val).lower():
                            # Äiá»u chá»‰nh Ä‘á»™ phÃ¹ há»£p
                            result['do_phu_hop'] = "Cao"
                            result['diem_so'] = round(min(0.95, score * 1.3), 2)
            
                results.append(result)
        
        # Sáº¯p xáº¿p káº¿t quáº£ theo Ä‘á»™ phÃ¹ há»£p náº¿u tÃ¬m theo thá»i gian
        if 'time_focus' in query_info['components'] and 'time_unit' in query_info['components']:
            time_unit = query_info['components']['time_unit']
            
            # Sáº¯p xáº¿p Ä‘á»ƒ Æ°u tiÃªn cÃ¡c káº¿t quáº£ cÃ³ thá»i gian khá»›p
            def time_sort_key(result):
                # Náº¿u cÃ³ trÆ°á»ng Ä‘á»‹nh_ká»³_thá»±c_hiá»‡n vÃ  nÃ³ chá»©a time_unit
                if 'Ä‘á»‹nh_ká»³_thá»±c_hiá»‡n' in result and time_unit in str(result['Ä‘á»‹nh_ká»³_thá»±c_hiá»‡n']).lower():
                    return (1, result['diem_so'])  # Æ¯u tiÃªn cao nháº¥t
                return (0, result['diem_so'])      # Æ¯u tiÃªn tháº¥p hÆ¡n
                
            results = sorted(results, key=time_sort_key, reverse=True)
        
        return {
            "query_info": query_info,
            "total_results": len(results),
            "results": results
        }

# âœ… Chá»©c nÄƒng lÆ°u vÃ  náº¡p lá»‹ch sá»­ há»™i thoáº¡i
def save_conversation(messages, conversation_name=None, path="./history"):
    # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
    if not os.path.exists(path):
        os.makedirs(path)
    
    # Táº¡o tÃªn file tá»« thá»i gian hoáº·c tÃªn Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
    if conversation_name:
        # LÃ m sáº¡ch tÃªn file
        conversation_name = ''.join(c for c in conversation_name if c.isalnum() or c in ' -_')
        filename = f"{path}/{conversation_name}.json"
    else:
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{path}/chat_{timestamp}.json"
    
    # LÆ°u há»™i thoáº¡i vÃ o file
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(messages, f, ensure_ascii=False, indent=2)
    
    return filename

def load_conversation(filename_or_index, path="./history"):
    # Kiá»ƒm tra náº¿u thÆ° má»¥c tá»“n táº¡i
    if not os.path.exists(path):
        return None, "ChÆ°a cÃ³ lá»‹ch sá»­ há»™i thoáº¡i nÃ o Ä‘Æ°á»£c lÆ°u."
    
    # Láº¥y danh sÃ¡ch file
    files = [f for f in os.listdir(path) if f.endswith('.json')]
    
    if not files:
        return None, "KhÃ´ng tÃ¬m tháº¥y file lá»‹ch sá»­ há»™i thoáº¡i nÃ o."
    
    # Sáº¯p xáº¿p theo thá»i gian táº¡o (má»›i nháº¥t trÆ°á»›c)
    files.sort(key=lambda x: os.path.getmtime(os.path.join(path, x)), reverse=True)
    
    filename = None
    # Náº¿u lÃ  sá»‘, láº¥y file theo index
    if str(filename_or_index).isdigit():
        index = int(filename_or_index)
        if 0 <= index < len(files):
            filename = os.path.join(path, files[index])
        else:
            return None, f"Chá»‰ sá»‘ khÃ´ng há»£p lá»‡. Vui lÃ²ng chá»n tá»« 0 Ä‘áº¿n {len(files)-1}."
    else:
        # Náº¿u lÃ  tÃªn file, tÃ¬m file phÃ¹ há»£p
        for file in files:
            if filename_or_index in file:
                filename = os.path.join(path, file)
                break
    
    if not filename:
        return None, f"KhÃ´ng tÃ¬m tháº¥y file '{filename_or_index}'. Sá»­ dá»¥ng '/list' Ä‘á»ƒ xem danh sÃ¡ch há»™i thoáº¡i."
    
    # Äá»c file
    try:
        with open(filename, "r", encoding="utf-8") as f:
            messages = json.load(f)
        return messages, f"ÄÃ£ táº£i lá»‹ch sá»­ há»™i thoáº¡i tá»« {filename}"
    except Exception as e:
        return None, f"Lá»—i khi Ä‘á»c file: {str(e)}"

def list_conversations(path="./history"):
    if not os.path.exists(path):
        return "ChÆ°a cÃ³ lá»‹ch sá»­ há»™i thoáº¡i nÃ o Ä‘Æ°á»£c lÆ°u."
    
    files = [f for f in os.listdir(path) if f.endswith('.json')]
    
    if not files:
        return "KhÃ´ng tÃ¬m tháº¥y file lá»‹ch sá»­ há»™i thoáº¡i nÃ o."
    
    # Sáº¯p xáº¿p theo thá»i gian táº¡o (má»›i nháº¥t trÆ°á»›c)
    files.sort(key=lambda x: os.path.getmtime(os.path.join(path, x)), reverse=True)
    
    result = "Danh sÃ¡ch há»™i thoáº¡i Ä‘Ã£ lÆ°u:\n"
    for i, file in enumerate(files):
        # Láº¥y thá»i gian táº¡o
        timestamp = datetime.datetime.fromtimestamp(os.path.getmtime(os.path.join(path, file)))
        result += f"{i}: {file} - {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\n"
    
    result += "\nSá»­ dá»¥ng '/load [sá»‘ thá»© tá»±]' hoáº·c '/load [tÃªn file]' Ä‘á»ƒ táº£i lá»‹ch sá»­."
    return result

# âœ… Step 2: Cáº¥u hÃ¬nh LLM
llm_cfg = {
    'model': 'qwen3-30b-a3b',
    'model_server': 'http://localhost:1234/v1',  # LM Studio máº·c Ä‘á»‹nh
    'api_key': 'EMPTY',
}

# âœ… Step 3: Táº¡o Assistant
assistant = Assistant(
    llm=llm_cfg,
    function_list=["tra_cuu_quy_trinh"],
    system_message="""Báº¡n lÃ  chuyÃªn gia vá» mÃ´ hÃ¬nh RACI cá»§a cÃ´ng ty, giÃºp tráº£ lá»i cÃ¢u há»i vá» quy trÃ¬nh cÃ´ng viá»‡c dá»±a trÃªn mÃ´ hÃ¬nh RACI.

NguyÃªn táº¯c lÃ m viá»‡c:
1. LuÃ´n gá»i tool tra_cuu_quy_trinh khi tráº£ lá»i cÃ¢u há»i vá» quy trÃ¬nh cÃ´ng viá»‡c
2. Náº¿u nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u JSON, hÃ£y biáº¿n Ä‘á»•i nÃ³ thÃ nh vÄƒn báº£n cÃ³ cáº¥u trÃºc rÃµ rÃ ng, dá»… Ä‘á»c
3. Náº¿u nhiá»u káº¿t quáº£, hÃ£y tÃ³m táº¯t Ä‘iá»ƒm chung vÃ  nÃªu rÃµ sá»± khÃ¡c biá»‡t
4. Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin, hÃ£y gá»£i Ã½ ngÆ°á»i dÃ¹ng cung cáº¥p thÃªm chi tiáº¿t vá» giai Ä‘oáº¡n, phÃ²ng ban, hoáº·c cÃ´ng viá»‡c cá»¥ thá»ƒ
5. Tráº£ lá»i ngáº¯n gá»n, sÃºc tÃ­ch, cÃ³ cáº¥u trÃºc rÃµ rÃ ng
6. Náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u tá»« tool, thÃ¬ hÃ£y nÃ³i rÃµ mÃ¬nh khÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u vÃ  muá»‘n tráº£ lá»i theo kiáº¿n thá»©c cá»§a mÃ´ hÃ¬nh khÃ´ng.

Khi cáº§n biáº¿t thÃªm thÃ´ng tin, hÃ£y há»i vá»:
- Giai Ä‘oáº¡n quy trÃ¬nh: Branding MKT, Sales Sourcing, Data Qualification, Approach, v.v.
- PhÃ²ng ban: Marketing, Kinh doanh, v.v.
- Loáº¡i cÃ´ng viá»‡c cá»¥ thá»ƒ
"""
)

# âœ… Step 4: Giao diá»‡n chat Ä‘Æ¡n giáº£n
messages = []
max_history = 6  # 3 cáº·p há»™i thoáº¡i (3 user + 3 assistant)

# Hiá»ƒn thá»‹ thÃ´ng tin chÃ o má»«ng
print("\n" + "="*50)
print("ğŸ¤– CHATBOT QUY TRÃŒNH CÃ”NG VIá»†C")
print("="*50)
print("CÃ¡c lá»‡nh Ä‘áº·c biá»‡t:")
print("/save [tÃªn] - LÆ°u há»™i thoáº¡i hiá»‡n táº¡i")
print("/load [sá»‘|tÃªn] - Táº£i lá»‹ch sá»­ há»™i thoáº¡i")
print("/list - Xem danh sÃ¡ch há»™i thoáº¡i Ä‘Ã£ lÆ°u")
print("/clear - XÃ³a lá»‹ch sá»­ há»™i thoáº¡i hiá»‡n táº¡i")
print("/exit - ThoÃ¡t chÆ°Æ¡ng trÃ¬nh")
print("="*50 + "\n")

while True:
    query = input("â“ CÃ¢u há»i: ").strip()
    if not query:
        continue
        
    # Xá»­ lÃ½ cÃ¡c lá»‡nh Ä‘áº·c biá»‡t
    if query.startswith("/"):
        cmd_parts = query.split(maxsplit=1)
        cmd = cmd_parts[0].lower()
        
        # Lá»‡nh thoÃ¡t
        if cmd == "/exit":
            print("ğŸ‘‹ Táº¡m biá»‡t! Háº¹n gáº·p láº¡i.")
            break
            
        # Lá»‡nh lÆ°u há»™i thoáº¡i
        elif cmd == "/save":
            name = cmd_parts[1] if len(cmd_parts) > 1 else None
            saved_file = save_conversation(messages, name)
            print(f"ğŸ¤– ÄÃ£ lÆ°u há»™i thoáº¡i vÃ o {saved_file}")
            continue
            
        # Lá»‡nh táº£i há»™i thoáº¡i
        elif cmd == "/load":
            if len(cmd_parts) < 2:
                print("ğŸ¤– Vui lÃ²ng cung cáº¥p sá»‘ thá»© tá»± hoáº·c tÃªn file. Sá»­ dá»¥ng /list Ä‘á»ƒ xem danh sÃ¡ch.")
            else:
                loaded_messages, message = load_conversation(cmd_parts[1])
                if loaded_messages:
                    messages = loaded_messages
                    print(f"ğŸ¤– {message}")
                else:
                    print(f"ğŸ¤– {message}")
            continue
            
        # Lá»‡nh liá»‡t kÃª há»™i thoáº¡i
        elif cmd == "/list":
            conversations_list = list_conversations()
            print(f"ğŸ¤– {conversations_list}")
            continue
            
        # Lá»‡nh xÃ³a lá»‹ch sá»­
        elif cmd == "/clear":
            messages = []
            print("ğŸ¤– ÄÃ£ xÃ³a lá»‹ch sá»­ há»™i thoáº¡i hiá»‡n táº¡i.")
            continue
    
    # Xá»­ lÃ½ cÃ¢u há»i bÃ¬nh thÆ°á»ng
    messages.append({'role': 'user', 'content': query})

    # Hiá»ƒn thá»‹ Ä‘ang xá»­ lÃ½
    loading_chars = "|/-\\"
    for i in range(5):
        print(f"\rğŸ¤– Äang suy nghÄ© {loading_chars[i % len(loading_chars)]}", end='', flush=True)
        time.sleep(0.2)
    print("\rğŸ¤– Tráº£ lá»i: ", end='', flush=True)
    
    # Gá»i trá»£ lÃ½ vÃ  xá»­ lÃ½ pháº£n há»“i
    response = []
    response_text = ''
    for r in assistant.run(messages=messages):
        chunk = r[-1]['content']
        print(chunk, end='', flush=True)
        response_text += chunk
        response.append(r[-1])
    messages.extend(response)
    
    # Giá»¯ láº¡i lá»‹ch sá»­ theo cáº·p há»™i thoáº¡i
    if len(messages) > max_history:
        # Chá»‰ giá»¯ láº¡i cÃ¡c cáº·p hoÃ n chá»‰nh, báº¯t Ä‘áº§u vá»›i user
        # TÃ¬m cÃ¡c cáº·p hoÃ n chá»‰nh tá»« cuá»‘i lÃªn
        new_messages = []
        pairs_count = 0
        i = len(messages) - 2  # Báº¯t Ä‘áº§u tá»« cáº·p cuá»‘i cÃ¹ng
        
        while i >= 0 and pairs_count < (max_history // 2):
            if messages[i]['role'] == 'user' and messages[i+1]['role'] == 'assistant':
                new_messages = [messages[i], messages[i+1]] + new_messages
                pairs_count += 1
                i -= 2
            else:
                i -= 1
                
        # Náº¿u tin nháº¯n cuá»‘i lÃ  user vÃ  chÆ°a Ä‘Æ°á»£c tráº£ lá»i
        if messages and messages[-1]['role'] == 'user' and messages[-1] not in new_messages:
            new_messages.append(messages[-1])
            
        messages = new_messages
    
    print()  # xuá»‘ng dÃ²ng sau tráº£ lá»i